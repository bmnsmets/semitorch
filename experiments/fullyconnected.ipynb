{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments\n",
    "\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data path = /home/bmnsmets/Documents/semitorch/data\n",
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import semitorch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"data path = {data_path}\\ndevice = {device}\")\n",
    "\n",
    "def split_dataset(dataset: torch.utils.data.Dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iris data\n",
    "[https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset: input features = 4, classes = 3, samples = 150\n"
     ]
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\n",
    "    os.path.join(data_path, \"iris.csv\"), index_col=0, dtype={\"Species\": \"string\"}\n",
    ")\n",
    "iris_x = torch.Tensor(iris_df.iloc[:, [0, 1, 2, 3]].to_numpy()).to(device)\n",
    "\n",
    "\n",
    "iris_y = (\n",
    "    iris_df[\"Species\"]\n",
    "    .map(\n",
    "        {\n",
    "            \"Iris-setosa\": 0,\n",
    "            \"Iris-versicolor\": 1,\n",
    "            \"Iris-virginica\": 2,\n",
    "        }\n",
    "    )\n",
    "    .to_numpy()\n",
    ")\n",
    "iris_y = torch.Tensor(iris_y).to(torch.int64).to(device)\n",
    "print(\n",
    "    f\"Iris dataset: input features = {iris_x.shape[1]}, classes = {torch.unique(iris_y).shape[0]}, samples = {len(iris_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(iris_x, dim=0, out=iris_x);\n",
    "\n",
    "iris_train, iris_test = split_dataset(torch.utils.data.TensorDataset(iris_x, iris_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load heart disease data\n",
    "\n",
    "[https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart disease dataset: input features = 13, classes = 2, samples = 303\n"
     ]
    }
   ],
   "source": [
    "heart_df = pd.read_csv(os.path.join(data_path, \"heart.csv\"))\n",
    "heart_x = (\n",
    "    torch.Tensor(heart_df.iloc[:, range(13)].to_numpy()).to(torch.float32).to(device)\n",
    ")\n",
    "heart_y = torch.Tensor(heart_df.iloc[:, -1].to_numpy()).to(torch.int64).to(device)\n",
    "\n",
    "print(\n",
    "    f\"Heart disease dataset: input features = {heart_x.shape[1]}, classes = {torch.unique(heart_y).shape[0]}, samples = {len(heart_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(heart_x, dim=0, out=heart_x);\n",
    "\n",
    "heart_train, heart_test = split_dataset(torch.utils.data.TensorDataset(heart_x, heart_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Naitzat data\n",
    "\n",
    "[https://github.com/topnn/topnn_framework](https://github.com/topnn/topnn_framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circles dataset: input features = 2, classes = 2, samples = 15950\n",
      "Rings dataset: input features = 3, classes = 2, samples = 45000\n",
      "Spheres dataset: input features = 3, classes = 2, samples = 37800\n"
     ]
    }
   ],
   "source": [
    "circles_x, circles_y = torch.load(\n",
    "    os.path.join(data_path, \"naitzat\", \"circles_type_8.pt\")\n",
    ")\n",
    "circles_train, circles_test = split_dataset(torch.utils.data.TensorDataset(circles_x, circles_y))\n",
    "print(\n",
    "    f\"Circles dataset: input features = {circles_x.shape[1]}, classes = {torch.unique(circles_y).shape[0]}, samples = {len(circles_y)}\"\n",
    ")\n",
    "\n",
    "rings_x, rings_y = torch.load(os.path.join(data_path, \"naitzat\", \"rings_9.pt\"))\n",
    "rings_train, rings_test = split_dataset(torch.utils.data.TensorDataset(rings_x, rings_y))\n",
    "print(\n",
    "    f\"Rings dataset: input features = {rings_x.shape[1]}, classes = {torch.unique(rings_y).shape[0]}, samples = {len(rings_y)}\"\n",
    ")\n",
    "\n",
    "spheres_x, spheres_y = torch.load(os.path.join(data_path, \"naitzat\", \"spheres_9.pt\"))\n",
    "spheres_train, spheres_test = split_dataset(torch.utils.data.TensorDataset(spheres_x, spheres_y))\n",
    "print(\n",
    "    f\"Spheres dataset: input features = {spheres_x.shape[1]}, classes = {torch.unique(spheres_y).shape[0]}, samples = {len(spheres_y)}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name: str, num_features: int, num_classes: int):\n",
    "    BACKBONE_FEATURES = 32\n",
    "\n",
    "    if model_name == \"linear_relu\":\n",
    "        backbone = nn.Sequential(\n",
    "            nn.Linear(num_features, BACKBONE_FEATURES),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(BACKBONE_FEATURES, BACKBONE_FEATURES),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(BACKBONE_FEATURES, BACKBONE_FEATURES),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(BACKBONE_FEATURES, BACKBONE_FEATURES),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    elif model_name == \"linear_maxplus\":\n",
    "        backbone = nn.Sequential()\n",
    "    else:\n",
    "        raise RuntimeError(\"Unknown model (%s)\" % model_name)\n",
    "    \n",
    "    head = nn.Linear(BACKBONE_FEATURES, num_classes, bias=False)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        OrderedDict([(\"backbone\", backbone), (\"head\", head)])\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y):\n",
    "    with torch.no_grad():\n",
    "        yout = model(x)\n",
    "        _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "        return (y==prediction).sum().item() / float(y.numel())\n",
    "\n",
    "\n",
    "\n",
    "def test(model, device, testloader):\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x = x.to(device)\n",
    "            accs.append(accuracy(model, x, y))\n",
    "    return sum(accs)/len(accs)\n",
    "\n",
    "\n",
    "def train(model, device, trainloader, testloader, optimizer, scheduler, loss, epochs):\n",
    "    accs = [] # list of accuracy on the test dataset for every epoch\n",
    "    trainaccs = [] # a list of the accuracies of all the training batches\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[6,4])\n",
    "    hdisplay = display.display(\"\", display_id=True)\n",
    "\n",
    "    for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "            trainaccs.append((y.cpu()==prediction).sum().item() / float(y.numel()))\n",
    "            l = loss(yout, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler != None:\n",
    "                scheduler.step()\n",
    "\n",
    "        accs.append(test(model, device, testloader))\n",
    "\n",
    "        ax.clear()\n",
    "        ax.set_xlim(0, epochs)\n",
    "        ax.set_ylim(0.75, 1.0)\n",
    "        ax.plot(np.linspace(0,len(accs),len(trainaccs)), \n",
    "            trainaccs, \".\", markersize=1.5, markerfacecolor=(0, 0, 1, 0.3))\n",
    "        ax.plot(np.linspace(1,len(accs),len(accs)), accs)\n",
    "        ax.text(0.6*epochs, 0.80, f\"max test acc = {max(accs):.2%}\", ha=\"center\", fontsize=10)\n",
    "        hdisplay.update(fig)\n",
    "        \n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    plt.close(fig)\n",
    "        \n",
    "\n",
    "def resetmodel(model: nn.Module) -> None:\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()\n",
    "    model.apply(fn=weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_relu_model_iris = create_model(\"linear_relu\", 4, 3)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "optimizer = torch.optim.AdamW(linear_relu_model_iris.parameters(), \n",
    "                lr=1e-2,\n",
    "                weight_decay=0.01\n",
    "            )\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                max_lr=1e-2,\n",
    "                anneal_strategy='linear',\n",
    "                pct_start=0.4,\n",
    "                three_phase=True,\n",
    "                final_div_factor=500.0,\n",
    "                div_factor=25.0,\n",
    "                steps_per_epoch=len(iris_train), \n",
    "                epochs=epochs\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
