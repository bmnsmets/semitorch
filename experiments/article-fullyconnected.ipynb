{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments\n",
    "\n",
    "This notebook contains the experiments with fully connected neural networks on the following datasets:\n",
    "- [Iris]([https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)) \n",
    "- [Heart Disease](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)\n",
    "- [Naitzat](https://github.com/topnn/topnn_framework) (circles, rings and spheres)\n",
    "- [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.5.0, llvm 15.0.4, commit 7b885c28, linux, python 3.10.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 09/18/23 10:56:43.301 193330] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=cuda\n",
      "data path = /home/bmnsmets/Documents/semitorch/data\n",
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import semitorch\n",
    "from semitorch import MultiLRScheduler, MultiOptimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from itertools import chain\n",
    "from typing import Union, Tuple\n",
    "\n",
    "# Reproducibility\n",
    "RNG_SEED = 42\n",
    "torch.manual_seed(RNG_SEED)\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed()\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"data path = {data_path}\\ndevice = {device}\")\n",
    "\n",
    "\n",
    "def split_dataset(dataset: torch.utils.data.Dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def resetmodel(model: nn.Module) -> None:\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()\n",
    "\n",
    "    model.apply(fn=weight_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load iris data\n",
    "[https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset: input features = 4, classes = 3, samples = 150\n"
     ]
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\n",
    "    os.path.join(data_path, \"iris.csv\"), index_col=0, dtype={\"Species\": \"string\"}\n",
    ")\n",
    "iris_x = torch.Tensor(iris_df.iloc[:, [0, 1, 2, 3]].to_numpy()).to(device)\n",
    "\n",
    "\n",
    "iris_y = (\n",
    "    iris_df[\"Species\"]\n",
    "    .map(\n",
    "        {\n",
    "            \"Iris-setosa\": 0,\n",
    "            \"Iris-versicolor\": 1,\n",
    "            \"Iris-virginica\": 2,\n",
    "        }\n",
    "    )\n",
    "    .to_numpy()\n",
    ")\n",
    "iris_y = torch.Tensor(iris_y).to(torch.int64).to(device)\n",
    "print(\n",
    "    f\"Iris dataset: input features = {iris_x.shape[1]}, classes = {torch.unique(iris_y).shape[0]}, samples = {len(iris_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(iris_x, dim=0, out=iris_x);\n",
    "\n",
    "iris_train, iris_test = split_dataset(torch.utils.data.TensorDataset(iris_x, iris_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load heart disease data\n",
    "\n",
    "[https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart disease dataset: input features = 13, classes = 2, samples = 303\n"
     ]
    }
   ],
   "source": [
    "heart_df = pd.read_csv(os.path.join(data_path, \"heart.csv\"))\n",
    "heart_x = (\n",
    "    torch.Tensor(heart_df.iloc[:, range(13)].to_numpy()).to(torch.float32).to(device)\n",
    ")\n",
    "heart_y = torch.Tensor(heart_df.iloc[:, -1].to_numpy()).to(torch.int64).to(device)\n",
    "\n",
    "print(\n",
    "    f\"Heart disease dataset: input features = {heart_x.shape[1]}, classes = {torch.unique(heart_y).shape[0]}, samples = {len(heart_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(heart_x, dim=0, out=heart_x);\n",
    "\n",
    "heart_train, heart_test = split_dataset(torch.utils.data.TensorDataset(heart_x, heart_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Naitzat data\n",
    "\n",
    "[https://github.com/topnn/topnn_framework](https://github.com/topnn/topnn_framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circles dataset: input features = 2, classes = 2, samples = 15950\n",
      "Rings dataset: input features = 3, classes = 2, samples = 45000\n",
      "Spheres dataset: input features = 3, classes = 2, samples = 37800\n"
     ]
    }
   ],
   "source": [
    "circles_x, circles_y = torch.load(\n",
    "    os.path.join(data_path, \"naitzat\", \"circles_type_8.pt\")\n",
    ")\n",
    "circles_train, circles_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(circles_x, circles_y)\n",
    ")\n",
    "print(\n",
    "    f\"Circles dataset: input features = {circles_x.shape[1]}, classes = {torch.unique(circles_y).shape[0]}, samples = {len(circles_y)}\"\n",
    ")\n",
    "\n",
    "rings_x, rings_y = torch.load(os.path.join(data_path, \"naitzat\", \"rings_9.pt\"))\n",
    "rings_train, rings_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(rings_x, rings_y)\n",
    ")\n",
    "print(\n",
    "    f\"Rings dataset: input features = {rings_x.shape[1]}, classes = {torch.unique(rings_y).shape[0]}, samples = {len(rings_y)}\"\n",
    ")\n",
    "\n",
    "spheres_x, spheres_y = torch.load(os.path.join(data_path, \"naitzat\", \"spheres_9.pt\"))\n",
    "spheres_train, spheres_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(spheres_x, spheres_y)\n",
    ")\n",
    "print(\n",
    "    f\"Spheres dataset: input features = {spheres_x.shape[1]}, classes = {torch.unique(spheres_y).shape[0]}, samples = {len(spheres_y)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load FashionMNIST data\n",
    "\n",
    "https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FashionMNIST dataset\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,),(0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,),(0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = FashionMNIST(root=data_path, train=True, download=True, transform=transforms_train)\n",
    "testset = FashionMNIST(root=data_path, train=False, download=True, transform=transforms_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train_loader = DataLoader(iris_train, batch_size=8, shuffle=True)\n",
    "iris_test_loader = DataLoader(iris_test, batch_size=len(iris_test), shuffle=False)\n",
    "\n",
    "heart_train_loader = DataLoader(heart_train, batch_size=32, shuffle=True)\n",
    "heart_test_loader = DataLoader(heart_test, batch_size=len(heart_test))\n",
    "\n",
    "circles_train_loader = DataLoader(circles_train, batch_size=16, shuffle=True)\n",
    "circles_test_loader = DataLoader(\n",
    "    circles_test, batch_size=len(circles_test), shuffle=True\n",
    ")\n",
    "\n",
    "rings_train_loader = DataLoader(rings_train, batch_size=16, shuffle=True)\n",
    "rings_test_loader = DataLoader(rings_test, batch_size=len(rings_test), shuffle=True)\n",
    "\n",
    "spheres_train_loader = DataLoader(spheres_train, batch_size=16, shuffle=True)\n",
    "spheres_test_loader = DataLoader(\n",
    "    spheres_test, batch_size=len(spheres_test), shuffle=True\n",
    ")\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(RNG_SEED)\n",
    "\n",
    "fashion_trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g,\n",
    ")\n",
    "fashion_testloader = DataLoader(testset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Baseline linear-ReLU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearReLU(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=2e-2, weight_decay=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=2e-2,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "        )\n",
    "        return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Tropical networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMaxPlus(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MaxPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MaxPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        return tropcial_optimizer_and_scheduler(self, epochs, steps_per_epoch)\n",
    "\n",
    "\n",
    "class LinearMinPlus(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MinPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MinPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        return tropcial_optimizer_and_scheduler(self, epochs, steps_per_epoch)\n",
    "\n",
    "\n",
    "def tropcial_optimizer_and_scheduler(\n",
    "    model: Union[LinearMaxPlus, LinearMinPlus], epochs: int, steps_per_epoch: int\n",
    "):\n",
    "    linear_params = chain(\n",
    "        model.stem.parameters(),\n",
    "        model.layer1[0].parameters(),\n",
    "        model.layer2[0].parameters(),\n",
    "        model.head.parameters(),\n",
    "    )\n",
    "    tropical_params = chain(model.layer1[1].parameters(), model.layer2[1].parameters())\n",
    "    opt1 = torch.optim.AdamW(linear_params, lr=2e-2, weight_decay=0.01)\n",
    "    sch1 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt1,\n",
    "        max_lr=2e-2,\n",
    "        anneal_strategy=\"linear\",\n",
    "        pct_start=0.3,\n",
    "        three_phase=True,\n",
    "        final_div_factor=1000.0,\n",
    "        div_factor=10.0,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    opt2 = torch.optim.AdamW(tropical_params, lr=2e-3, weight_decay=0.01)\n",
    "    sch2 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt2,\n",
    "        max_lr=2e-3,\n",
    "        anneal_strategy=\"linear\",\n",
    "        pct_start=0.3,\n",
    "        three_phase=True,\n",
    "        final_div_factor=1000.0,\n",
    "        div_factor=10.0,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    optimizer = MultiOptimizer(opt1, opt2)\n",
    "    scheduler = MultiLRScheduler(sch1, sch2)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n",
      "688\n"
     ]
    }
   ],
   "source": [
    "m = LinearMinPlus(8,3)\n",
    "print(count_parameters(m))\n",
    "m2 = LinearReLU(8,3)\n",
    "print(count_parameters(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch200cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
