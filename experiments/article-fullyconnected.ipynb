{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments\n",
    "\n",
    "This notebook contains the experiments with fully connected neural networks on the following datasets:\n",
    "- [Iris]([https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)) \n",
    "- [Heart Disease](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)\n",
    "- [Naitzat](https://github.com/topnn/topnn_framework) (circles, rings and spheres)\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.6.0, llvm 15.0.1, commit f1c6fbbd, win, python 3.11.4\n",
      "[Taichi] Starting on arch=cuda\n",
      "data path = c:\\Users\\Bart Smets\\Documents\\semitorch\\data\n",
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import semitorch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from semitorch import MultiLRScheduler, MultiOptimizer\n",
    "from itertools import chain\n",
    "from typing import Union, Tuple\n",
    "\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"data path = {data_path}\\ndevice = {device}\")\n",
    "\n",
    "\n",
    "def split_dataset(dataset: torch.utils.data.Dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def resetmodel(model: nn.Module) -> None:\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()\n",
    "\n",
    "    model.apply(fn=weight_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load iris data\n",
    "[https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset: input features = 4, classes = 3, samples = 150\n"
     ]
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\n",
    "    os.path.join(data_path, \"iris.csv\"), index_col=0, dtype={\"Species\": \"string\"}\n",
    ")\n",
    "iris_x = torch.Tensor(iris_df.iloc[:, [0, 1, 2, 3]].to_numpy()).to(device)\n",
    "\n",
    "\n",
    "iris_y = (\n",
    "    iris_df[\"Species\"]\n",
    "    .map(\n",
    "        {\n",
    "            \"Iris-setosa\": 0,\n",
    "            \"Iris-versicolor\": 1,\n",
    "            \"Iris-virginica\": 2,\n",
    "        }\n",
    "    )\n",
    "    .to_numpy()\n",
    ")\n",
    "iris_y = torch.Tensor(iris_y).to(torch.int64).to(device)\n",
    "print(\n",
    "    f\"Iris dataset: input features = {iris_x.shape[1]}, classes = {torch.unique(iris_y).shape[0]}, samples = {len(iris_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(iris_x, dim=0, out=iris_x);\n",
    "\n",
    "iris_train, iris_test = split_dataset(torch.utils.data.TensorDataset(iris_x, iris_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load heart disease data\n",
    "\n",
    "[https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart disease dataset: input features = 13, classes = 2, samples = 303\n"
     ]
    }
   ],
   "source": [
    "heart_df = pd.read_csv(os.path.join(data_path, \"heart.csv\"))\n",
    "heart_x = (\n",
    "    torch.Tensor(heart_df.iloc[:, range(13)].to_numpy()).to(torch.float32).to(device)\n",
    ")\n",
    "heart_y = torch.Tensor(heart_df.iloc[:, -1].to_numpy()).to(torch.int64).to(device)\n",
    "\n",
    "print(\n",
    "    f\"Heart disease dataset: input features = {heart_x.shape[1]}, classes = {torch.unique(heart_y).shape[0]}, samples = {len(heart_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(heart_x, dim=0, out=heart_x);\n",
    "\n",
    "heart_train, heart_test = split_dataset(torch.utils.data.TensorDataset(heart_x, heart_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Naitzat data\n",
    "\n",
    "[https://github.com/topnn/topnn_framework](https://github.com/topnn/topnn_framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circles dataset: input features = 2, classes = 2, samples = 15950\n",
      "Rings dataset: input features = 3, classes = 2, samples = 45000\n",
      "Spheres dataset: input features = 3, classes = 2, samples = 37800\n"
     ]
    }
   ],
   "source": [
    "circles_x, circles_y = torch.load(\n",
    "    os.path.join(data_path, \"naitzat\", \"circles_type_8.pt\")\n",
    ")\n",
    "circles_train, circles_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(circles_x, circles_y)\n",
    ")\n",
    "print(\n",
    "    f\"Circles dataset: input features = {circles_x.shape[1]}, classes = {torch.unique(circles_y).shape[0]}, samples = {len(circles_y)}\"\n",
    ")\n",
    "\n",
    "rings_x, rings_y = torch.load(os.path.join(data_path, \"naitzat\", \"rings_9.pt\"))\n",
    "rings_train, rings_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(rings_x, rings_y)\n",
    ")\n",
    "print(\n",
    "    f\"Rings dataset: input features = {rings_x.shape[1]}, classes = {torch.unique(rings_y).shape[0]}, samples = {len(rings_y)}\"\n",
    ")\n",
    "\n",
    "spheres_x, spheres_y = torch.load(os.path.join(data_path, \"naitzat\", \"spheres_9.pt\"))\n",
    "spheres_train, spheres_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(spheres_x, spheres_y)\n",
    ")\n",
    "print(\n",
    "    f\"Spheres dataset: input features = {spheres_x.shape[1]}, classes = {torch.unique(spheres_y).shape[0]}, samples = {len(spheres_y)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Baseline linear-ReLU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearReLU(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=2e-2, weight_decay=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=2e-2,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "        )\n",
    "        return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Tropical networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMaxPlus(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MaxPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MaxPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        return tropcial_optimizer_and_scheduler(self, epochs, steps_per_epoch)\n",
    "\n",
    "\n",
    "class LinearMinPlus(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MinPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MinPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        return tropcial_optimizer_and_scheduler(self, epochs, steps_per_epoch)\n",
    "\n",
    "\n",
    "def tropcial_optimizer_and_scheduler(\n",
    "    model: Union[LinearMaxPlus, LinearMinPlus], epochs: int, steps_per_epoch: int\n",
    "):\n",
    "    linear_params = chain(\n",
    "        model.stem.parameters(),\n",
    "        model.layer1[0].parameters(),\n",
    "        model.layer2[0].parameters(),\n",
    "        model.head.parameters(),\n",
    "    )\n",
    "    tropical_params = chain(model.layer1[1].parameters(), model.layer2[1].parameters())\n",
    "    opt1 = torch.optim.AdamW(linear_params, lr=2e-2, weight_decay=0.01)\n",
    "    sch1 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt1,\n",
    "        max_lr=2e-2,\n",
    "        anneal_strategy=\"linear\",\n",
    "        pct_start=0.3,\n",
    "        three_phase=True,\n",
    "        final_div_factor=1000.0,\n",
    "        div_factor=10.0,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    opt2 = torch.optim.AdamW(tropical_params, lr=2e-3, weight_decay=0.01)\n",
    "    sch2 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt2,\n",
    "        max_lr=2e-3,\n",
    "        anneal_strategy=\"linear\",\n",
    "        pct_start=0.3,\n",
    "        three_phase=True,\n",
    "        final_div_factor=1000.0,\n",
    "        div_factor=10.0,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    optimizer = MultiOptimizer(opt1, opt2)\n",
    "    scheduler = MultiLRScheduler(sch1, sch2)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n",
      "688\n"
     ]
    }
   ],
   "source": [
    "m = LinearMinPlus(8,3)\n",
    "print(count_parameters(m))\n",
    "m2 = LinearReLU(8,3)\n",
    "print(count_parameters(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch200cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
