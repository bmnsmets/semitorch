{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments\n",
    "\n",
    "This notebook contains the experiments with fully connected neural networks on the following datasets:\n",
    "- [Iris]([https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)) \n",
    "- [Heart Disease](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)\n",
    "- [Naitzat](https://github.com/topnn/topnn_framework) (circles, rings and spheres)\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.5.0, llvm 15.0.4, commit 7b885c28, linux, python 3.10.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 09/15/23 13:13:33.017 173961] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] Starting on arch=cuda\n",
      "data path = /home/bmnsmets/Documents/semitorch/data\n",
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import semitorch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from semitorch import MultiLRScheduler, MultiOptimizer\n",
    "from itertools import chain\n",
    "from typing import Union, Tuple\n",
    "\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"data path = {data_path}\\ndevice = {device}\")\n",
    "\n",
    "\n",
    "def split_dataset(dataset: torch.utils.data.Dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def resetmodel(model: nn.Module) -> None:\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()\n",
    "\n",
    "    model.apply(fn=weight_reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load iris data\n",
    "[https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset: input features = 4, classes = 3, samples = 150\n"
     ]
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\n",
    "    os.path.join(data_path, \"iris.csv\"), index_col=0, dtype={\"Species\": \"string\"}\n",
    ")\n",
    "iris_x = torch.Tensor(iris_df.iloc[:, [0, 1, 2, 3]].to_numpy()).to(device)\n",
    "\n",
    "\n",
    "iris_y = (\n",
    "    iris_df[\"Species\"]\n",
    "    .map(\n",
    "        {\n",
    "            \"Iris-setosa\": 0,\n",
    "            \"Iris-versicolor\": 1,\n",
    "            \"Iris-virginica\": 2,\n",
    "        }\n",
    "    )\n",
    "    .to_numpy()\n",
    ")\n",
    "iris_y = torch.Tensor(iris_y).to(torch.int64).to(device)\n",
    "print(\n",
    "    f\"Iris dataset: input features = {iris_x.shape[1]}, classes = {torch.unique(iris_y).shape[0]}, samples = {len(iris_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(iris_x, dim=0, out=iris_x);\n",
    "\n",
    "iris_train, iris_test = split_dataset(torch.utils.data.TensorDataset(iris_x, iris_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load heart disease data\n",
    "\n",
    "[https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart disease dataset: input features = 13, classes = 2, samples = 303\n"
     ]
    }
   ],
   "source": [
    "heart_df = pd.read_csv(os.path.join(data_path, \"heart.csv\"))\n",
    "heart_x = (\n",
    "    torch.Tensor(heart_df.iloc[:, range(13)].to_numpy()).to(torch.float32).to(device)\n",
    ")\n",
    "heart_y = torch.Tensor(heart_df.iloc[:, -1].to_numpy()).to(torch.int64).to(device)\n",
    "\n",
    "print(\n",
    "    f\"Heart disease dataset: input features = {heart_x.shape[1]}, classes = {torch.unique(heart_y).shape[0]}, samples = {len(heart_y)}\"\n",
    ")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(heart_x, dim=0, out=heart_x);\n",
    "\n",
    "heart_train, heart_test = split_dataset(torch.utils.data.TensorDataset(heart_x, heart_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Naitzat data\n",
    "\n",
    "[https://github.com/topnn/topnn_framework](https://github.com/topnn/topnn_framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circles dataset: input features = 2, classes = 2, samples = 15950\n",
      "Rings dataset: input features = 3, classes = 2, samples = 45000\n",
      "Spheres dataset: input features = 3, classes = 2, samples = 37800\n"
     ]
    }
   ],
   "source": [
    "circles_x, circles_y = torch.load(\n",
    "    os.path.join(data_path, \"naitzat\", \"circles_type_8.pt\")\n",
    ")\n",
    "circles_train, circles_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(circles_x, circles_y)\n",
    ")\n",
    "print(\n",
    "    f\"Circles dataset: input features = {circles_x.shape[1]}, classes = {torch.unique(circles_y).shape[0]}, samples = {len(circles_y)}\"\n",
    ")\n",
    "\n",
    "rings_x, rings_y = torch.load(os.path.join(data_path, \"naitzat\", \"rings_9.pt\"))\n",
    "rings_train, rings_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(rings_x, rings_y)\n",
    ")\n",
    "print(\n",
    "    f\"Rings dataset: input features = {rings_x.shape[1]}, classes = {torch.unique(rings_y).shape[0]}, samples = {len(rings_y)}\"\n",
    ")\n",
    "\n",
    "spheres_x, spheres_y = torch.load(os.path.join(data_path, \"naitzat\", \"spheres_9.pt\"))\n",
    "spheres_train, spheres_test = split_dataset(\n",
    "    torch.utils.data.TensorDataset(spheres_x, spheres_y)\n",
    ")\n",
    "print(\n",
    "    f\"Spheres dataset: input features = {spheres_x.shape[1]}, classes = {torch.unique(spheres_y).shape[0]}, samples = {len(spheres_y)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Baseline linear-ReLU network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearReLU(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=2e-2, weight_decay=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=2e-2,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=epochs,\n",
    "        )\n",
    "        return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Tropical networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearMaxPlus(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MaxPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2, bias=False),\n",
    "            semitorch.MaxPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        return tropcial_optimizer_and_scheduler(self, epochs, steps_per_epoch)\n",
    "\n",
    "\n",
    "class LinearMinPlus(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int, width: int = 16):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Linear(num_features, width, bias=False)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2),\n",
    "            semitorch.MinPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(width, width // 2),\n",
    "            semitorch.MinPlus(width // 2, width, bias=False),\n",
    "        )\n",
    "        self.head = nn.Linear(width, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.stem(x)\n",
    "        y = y + self.layer1(y)\n",
    "        y = y + self.layer2(y)\n",
    "        return self.head(y)\n",
    "\n",
    "    def get_optimizer_and_scheduler(self, epochs: int, steps_per_epoch: int):\n",
    "        return tropcial_optimizer_and_scheduler(self, epochs, steps_per_epoch)\n",
    "\n",
    "\n",
    "def tropcial_optimizer_and_scheduler(\n",
    "    model: Union[LinearMaxPlus, LinearMinPlus], epochs: int, steps_per_epoch: int\n",
    "):\n",
    "    linear_params = chain(\n",
    "        model.stem.parameters(),\n",
    "        model.layer1[0].parameters(),\n",
    "        model.layer2[0].parameters(),\n",
    "        model.head.parameters(),\n",
    "    )\n",
    "    tropical_params = chain(model.layer1[1].parameters(), model.layer2[1].parameters())\n",
    "    opt1 = torch.optim.AdamW(linear_params, lr=2e-2, weight_decay=0.01)\n",
    "    sch1 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt1,\n",
    "        max_lr=2e-2,\n",
    "        anneal_strategy=\"linear\",\n",
    "        pct_start=0.3,\n",
    "        three_phase=True,\n",
    "        final_div_factor=1000.0,\n",
    "        div_factor=10.0,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    opt2 = torch.optim.AdamW(tropical_params, lr=2e-3, weight_decay=0.01)\n",
    "    sch2 = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt2,\n",
    "        max_lr=2e-3,\n",
    "        anneal_strategy=\"linear\",\n",
    "        pct_start=0.3,\n",
    "        three_phase=True,\n",
    "        final_div_factor=1000.0,\n",
    "        div_factor=10.0,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    optimizer = MultiOptimizer(opt1, opt2)\n",
    "    scheduler = MultiLRScheduler(sch1, sch2)\n",
    "    return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'params': [Parameter containing:\n",
       "   tensor([[-0.0000, 0.9767, 0.6091, 1.7938, 0.9432, 0.6237, 0.6989, 0.7063],\n",
       "           [0.1759, -0.0000, 0.5223, 1.5543, 1.3091, 1.3036, 0.9178, 1.3815],\n",
       "           [0.5379, 1.3517, -0.0000, 1.1011, 0.8468, 0.7559, 1.8626, 0.1780],\n",
       "           [0.6816, 1.5950, 0.5229, -0.0000, 0.4829, 1.5725, 0.6988, 0.3888],\n",
       "           [1.1356, 1.0427, 1.6987, 0.1961, -0.0000, 0.1438, 0.3406, 0.3092],\n",
       "           [0.8412, 0.4920, 1.2269, 1.2376, 1.0290, -0.0000, 1.6656, 1.7457],\n",
       "           [0.3278, 0.5030, 1.5998, 0.2169, 1.6464, 1.2414, -0.0000, 1.7436],\n",
       "           [0.6405, 0.4883, 1.0282, 0.7138, 0.2517, 1.1944, 0.7824, -0.0000],\n",
       "           [0.6290, 0.4233, 0.9666, 1.0422, 0.8453, 0.2658, 1.1203, 0.6654],\n",
       "           [1.4122, 0.6999, 1.0692, 1.1291, 0.8273, 1.0074, 0.9117, 1.0845],\n",
       "           [0.7372, 0.9981, 0.7578, 1.3645, 1.8094, 1.2495, 0.7450, 1.5839],\n",
       "           [0.6765, 1.2742, 0.9877, 0.6077, 0.1738, 1.0234, 1.5932, 0.9410],\n",
       "           [1.1489, 0.3993, 1.1170, 1.4764, 0.8988, 0.2441, 1.2510, 0.9210],\n",
       "           [0.2781, 1.2700, 0.6122, 1.6436, 0.6964, 0.3325, 1.2945, 0.5690],\n",
       "           [0.6167, 1.2322, 0.3568, 1.1540, 1.6916, 0.6790, 0.5003, 1.8040],\n",
       "           [0.5429, 0.8621, 1.0220, 0.2900, 1.0418, 1.6820, 0.9989, 0.8449]],\n",
       "          requires_grad=True),\n",
       "   Parameter containing:\n",
       "   tensor([[-0.0000, 0.9056, 0.8186, 0.8779, 1.6541, 1.3398, 0.7802, 1.0941],\n",
       "           [1.1553, -0.0000, 1.8523, 1.3583, 0.9139, 1.2506, 0.2163, 0.3043],\n",
       "           [0.2816, 1.7121, -0.0000, 1.1432, 1.7777, 0.6753, 0.7914, 1.8326],\n",
       "           [0.2927, 1.6308, 0.4367, -0.0000, 1.7226, 1.4853, 1.1588, 0.9170],\n",
       "           [1.5821, 1.4935, 1.2869, 1.4168, -0.0000, 1.8169, 0.6137, 0.2743],\n",
       "           [0.5489, 1.7091, 0.9967, 1.3358, 1.2148, -0.0000, 0.5754, 1.1337],\n",
       "           [1.0115, 0.9286, 1.4008, 1.5253, 0.3955, 0.4827, -0.0000, 0.8637],\n",
       "           [1.2009, 1.6307, 1.2335, 0.9455, 1.3561, 0.9672, 0.8985, -0.0000],\n",
       "           [1.7891, 0.7005, 1.3273, 1.4383, 1.4901, 0.6559, 1.6995, 1.1864],\n",
       "           [1.3903, 0.9130, 0.8109, 1.6396, 1.6373, 0.6798, 1.4238, 0.5803],\n",
       "           [0.6436, 0.5422, 1.3939, 1.5988, 0.1716, 0.5573, 0.9440, 1.0297],\n",
       "           [0.1778, 0.3110, 0.8042, 0.7075, 0.5469, 0.2590, 1.4232, 1.0925],\n",
       "           [1.1940, 0.7314, 1.4020, 0.4591, 0.8569, 0.4688, 1.2903, 1.7940],\n",
       "           [1.1673, 1.7086, 0.2962, 1.2004, 1.3996, 0.4520, 0.2366, 1.7662],\n",
       "           [1.4679, 1.5156, 0.9531, 0.1621, 1.7182, 1.6661, 0.5070, 0.5180],\n",
       "           [0.5244, 1.8326, 1.4484, 0.4152, 0.5392, 0.4748, 0.8592, 1.8251]],\n",
       "          requires_grad=True)],\n",
       "  'lr': 0.0002,\n",
       "  'betas': (0.95, 0.999),\n",
       "  'eps': 1e-08,\n",
       "  'weight_decay': 0.01,\n",
       "  'amsgrad': False,\n",
       "  'foreach': None,\n",
       "  'maximize': False,\n",
       "  'capturable': False,\n",
       "  'differentiable': False,\n",
       "  'fused': None,\n",
       "  'initial_lr': 0.0002,\n",
       "  'max_lr': 0.002,\n",
       "  'min_lr': 2.0000000000000002e-07,\n",
       "  'max_momentum': 0.95,\n",
       "  'base_momentum': 0.85}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearMinPlus(8,3)\n",
    "m.get_optimizer_and_scheduler(10,10)[0].optimizers[1].param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch200cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
