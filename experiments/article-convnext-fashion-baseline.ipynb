{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNeXt on FashionMNIST \n",
    "__(linear-ReLU baseline)__\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmnsmets/miniconda3/envs/torch21/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'semitorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscheduler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcosine_lr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CosineLRScheduler\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msemitorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FashionMNIST\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'semitorch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import timm.data\n",
    "import random\n",
    "import os\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "import semitorch\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from itertools import chain\n",
    "from semitorch import MultiOptimizer, MultiLRScheduler\n",
    "\n",
    "# Reproducibility\n",
    "RNG_SEED = 43\n",
    "torch.manual_seed(RNG_SEED)\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def get_lr_per_epoch(scheduler, num_epoch):\n",
    "    lr_per_epoch = []\n",
    "    for epoch in range(num_epoch):\n",
    "        lr_per_epoch.append(scheduler._get_values(epoch))\n",
    "    return lr_per_epoch\n",
    "\n",
    "def resetmodel(model: nn.Module) -> None:\n",
    "    @torch.no_grad()\n",
    "    def weight_reset(m: nn.Module):\n",
    "        reset_parameters = getattr(m, \"reset_parameters\", None)\n",
    "        if callable(reset_parameters):\n",
    "            m.reset_parameters()\n",
    "\n",
    "    model.apply(fn=weight_reset)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# path to data sets and device to work on\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"data path = {data_path}\\ndevice = {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torch21' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torch21 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Load FashionMNIST dataset\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "        transforms.Resize((16, 16), antialias=True),\n",
    "        # transforms.RandomResizedCrop(\n",
    "        #     (16, 16), scale=(0.9, 1.0), ratio=(0.9, 1.1), antialias=True\n",
    "        # ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "        transforms.Resize((16, 16), antialias=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fashion_train = FashionMNIST(\n",
    "    root=data_path, train=True, download=True, transform=transforms_train\n",
    ")\n",
    "fashion_test = FashionMNIST(\n",
    "    root=data_path, train=False, download=True, transform=transforms_test\n",
    ")\n",
    "\n",
    "fashion_num_features = fashion_test[0][0].shape[1] * fashion_test[0][0].shape[1]\n",
    "fashion_num_classes = torch.unique(fashion_test.targets).shape[0]\n",
    "\n",
    "print(\n",
    "    f\"FashionMNIST dataset: input features = {fashion_test[0][0].shape[1]}x{fashion_test[0][0].shape[1]}, classes = {torch.unique(fashion_test.targets).shape[0]}, samples = {len(fashion_train)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torch21' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torch21 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "num_workers = 4\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(RNG_SEED)\n",
    "\n",
    "fashion_train_loader = DataLoader(\n",
    "    fashion_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    generator=g,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "fashion_test_loader = DataLoader(\n",
    "    fashion_test, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torch21' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torch21 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "convnext_st_classic_atto = timm.create_model(\n",
    "    \"convnext_st_classic_atto\",\n",
    "    in_chans=1,\n",
    "    patch_size=1,\n",
    "    num_classes=10,\n",
    ")\n",
    "convnext_st_classic_atto = convnext_st_classic_atto.to(device)\n",
    "\n",
    "print(\n",
    "    f\"convnext_st_classic_atto has {count_parameters(convnext_st_classic_atto):,} parameters\"\n",
    ")\n",
    "\n",
    "def check_parameter_count(m):\n",
    "    linear = sum(p.numel() for p in m.linear_parameters() if p.requires_grad)\n",
    "    nonlinear = sum(p.numel() for p in m.nonlinear_parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "    assert total == linear + nonlinear\n",
    "    return\n",
    "\n",
    "check_parameter_count(convnext_st_classic_atto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torch21' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torch21 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    with torch.no_grad():\n",
    "        yout = model(x)\n",
    "        _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "        return (y==prediction).sum().item() / float(y.numel())\n",
    "\n",
    "\n",
    "def test(model, device, testloader):\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x = x.to(device)\n",
    "            accs.append(accuracy(model, x, y))\n",
    "    return sum(accs)/len(accs)\n",
    "\n",
    "\n",
    "def train(model, device, trainloader, testloader, optimizer, scheduler, loss, epochs):\n",
    "    accs = [] # list of accuracy on the test dataset for every epoch\n",
    "    trainaccs = [] # a list of the accuracies of all the training batches\n",
    "    epoch_len = len(trainloader)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[4,3])\n",
    "    hdisplay = display.display(\"\", display_id=True)\n",
    "\n",
    "    for epoch in trange(epochs):\n",
    "        model.train()\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "            trainaccs.append((y.cpu()==prediction).sum().item() / float(y.numel()))\n",
    "            l = loss(yout, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler != None:\n",
    "                scheduler.step(epoch)\n",
    "\n",
    "        accs.append(test(model, device, testloader))\n",
    "\n",
    "        ax.clear()\n",
    "        ax.set_xlim(0, epochs)\n",
    "        ax.set_ylim(0.75, 1.0)\n",
    "        ax.plot(np.linspace(0,len(accs),len(trainaccs)), \n",
    "            trainaccs, \".\", markersize=1.5, markerfacecolor=(0, 0, 1, 0.3))\n",
    "        ax.plot(np.linspace(1,len(accs),len(accs)), accs)\n",
    "        ax.text(0.6*epochs, 0.80, f\"max test acc = {max(accs):.2%}\", ha=\"center\", fontsize=10)\n",
    "        hdisplay.update(fig)\n",
    "        \n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    plt.close(fig)\n",
    "    return sum(trainaccs[-epoch_len:]) / len(trainaccs[-epoch_len:]), max(accs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torch21' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torch21 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "convnext_st_classic_atto.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torch21' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torch21 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "epochs = 50\n",
    "base_lr = 4e-3\n",
    "\n",
    "optimizer = torch.optim.AdamW(convnext_st_classic_atto.parameters(), lr=base_lr, weight_decay=5e-3)\n",
    "scheduler = CosineLRScheduler(\n",
    "    optimizer,\n",
    "    t_initial=epochs,\n",
    "    warmup_t=5,\n",
    "    warmup_lr_init=base_lr/25,\n",
    "    lr_min=base_lr/500,\n",
    ")\n",
    "# lr_per_epoch = get_lr_per_epoch(scheduler, epochs)\n",
    "# plt.plot([i for i in range(epochs)], lr_per_epoch, label=\"With warmup\")\n",
    "# plt.show()\n",
    "\n",
    "train(\n",
    "    convnext_st_classic_atto,\n",
    "    device,\n",
    "    fashion_train_loader,\n",
    "    fashion_test_loader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    loss,\n",
    "    epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'torch21' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n torch21 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch200cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
