{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch import Tensor\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn1(x: Tensor, a: Tensor) -> Tensor:\n",
    "    mu = 1.0\n",
    "    x = torch.exp(mu * x)\n",
    "    a = torch.exp(mu * a)\n",
    "    y = F.linear(x, a)\n",
    "    y = torch.log(y) / mu\n",
    "    return y\n",
    "\n",
    "\n",
    "def fn2(x: Tensor, a: Tensor) -> Tensor:\n",
    "    return checkpoint(fn1, x, a)\n",
    "\n",
    "\n",
    "x = torch.randn(10000, 1000, requires_grad=True).to(device)\n",
    "a = torch.randn(500, 1000, requires_grad=True).to(device)\n",
    "grad_y = torch.rand(10000, 500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.34 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n100 -r1 \n",
    "x1=x.detach().requires_grad_(True)\n",
    "a1=a.detach().requires_grad_(True)\n",
    "\n",
    "y1 = fn1(x1, a1)\n",
    "y1.backward(grad_y)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n100 -r1\n",
    "x2=x.detach().requires_grad_(True)\n",
    "a2=a.detach().requires_grad_(True)\n",
    "\n",
    "y2 = fn2(x2, a2)\n",
    "y2.backward(grad_y)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmnsmets/miniconda3/envs/pytorch200cu118/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    }
   ],
   "source": [
    "y1 = fn1(x.detach(), a.detach())\n",
    "y2 = fn2(x.detach(), a.detach())\n",
    "assert y1.allclose(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tropical1(x:Tensor, a:Tensor) -> Tensor:\n",
    "    return torch.max(x.unsqueeze(-2) + a, dim=-1)[0]\n",
    "\n",
    "def tropical2(x: Tensor, a: Tensor) -> Tensor:\n",
    "    return checkpoint(tropical1, x, a)\n",
    "\n",
    "x = torch.randn(100, 1000, requires_grad=True).to(device)\n",
    "a = torch.randn(500, 1000, requires_grad=True).to(device)\n",
    "grad_y = torch.rand(100, 500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.22 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n100 -r1 \n",
    "x1=x.detach().requires_grad_(True)\n",
    "a1=a.detach().requires_grad_(True)\n",
    "\n",
    "y1 = tropical1(x1, a1)\n",
    "y1.backward(grad_y)\n",
    "torch.cuda.synchronize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.86 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n100 -r1 \n",
    "x1=x.detach().requires_grad_(True)\n",
    "a1=a.detach().requires_grad_(True)\n",
    "\n",
    "y1 = tropical2(x1, a1)\n",
    "y1.backward(grad_y)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        aten::unsqueeze         0.63%      35.000us         0.74%      41.000us      41.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::as_strided         0.14%       8.000us         0.14%       8.000us       2.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                              aten::add        71.59%       3.961ms        72.33%       4.002ms       4.002ms       1.057ms        65.49%       1.057ms       1.057ms           0 b           0 b     190.73 Mb     190.73 Mb             1  \n",
      "                                       cudaLaunchKernel         0.92%      51.000us         0.92%      51.000us      25.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.057ms        65.49%       1.057ms       1.057ms           0 b           0 b           0 b           0 b             1  \n",
      "                                              aten::max         0.94%      52.000us         1.16%      64.000us      64.000us     557.000us        34.51%     557.000us     557.000us           0 b           0 b     586.50 Kb     586.50 Kb             1  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    -190.73 Mb    -190.73 Mb             1  \n",
      "                                  cudaDeviceSynchronize        25.77%       1.426ms        25.77%       1.426ms       1.426ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     557.000us        34.51%     557.000us     557.000us           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.533ms\n",
      "Self CUDA time total: 1.614ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-07-12 15:38:10 250074:250074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "STAGE:2023-07-12 15:38:10 250074:250074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-07-12 15:38:10 250074:250074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(100, 1000, requires_grad=True).to(device)\n",
    "a = torch.randn(500, 1000, requires_grad=True).to(device)\n",
    "grad_y = torch.rand(100, 500).to(device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True) as prof:\n",
    "    y = tropical1(x, a)\n",
    "\n",
    "print(prof.key_averages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     CheckpointFunction        28.30%       2.568ms        30.14%       2.735ms       2.735ms       0.000us         0.00%       6.803ms       6.803ms       5.73 Kb       5.73 Kb     195.50 Kb    -191.12 Mb             1  \n",
      "                                  cudaStreamIsCapturing         0.02%       2.000us         0.02%       2.000us       1.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                        aten::unsqueeze         0.13%      12.000us         0.17%      15.000us      15.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "                                       aten::as_strided         0.22%      20.000us         0.22%      20.000us       6.667us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             3  \n",
      "                                              aten::add         0.36%      33.000us         0.77%      70.000us      70.000us       4.920ms        72.32%       4.920ms       4.920ms           0 b           0 b     190.73 Mb     190.73 Mb             1  \n",
      "                                       cudaLaunchKernel         0.61%      55.000us         0.61%      55.000us      27.500us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
      "                                              aten::max         0.50%      45.000us         0.88%      80.000us      80.000us       1.883ms        27.68%       1.883ms       1.883ms           0 b           0 b     586.50 Kb     586.50 Kb             1  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.920ms        72.32%       4.920ms       4.920ms           0 b           0 b           0 b           0 b             1  \n",
      "                                               [memory]         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us           0 b           0 b    -586.50 Kb    -586.50 Kb             2  \n",
      "                                  cudaDeviceSynchronize        69.86%       6.338ms        69.86%       6.338ms       6.338ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.883ms        27.68%       1.883ms       1.883ms           0 b           0 b           0 b           0 b             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 9.073ms\n",
      "Self CUDA time total: 6.803ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-07-12 15:38:32 250074:250074 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n",
      "[W CPUAllocator.cpp:235] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n",
      "STAGE:2023-07-12 15:38:32 250074:250074 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2023-07-12 15:38:32 250074:250074 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(100, 1000, requires_grad=True).to(device)\n",
    "a = torch.randn(500, 1000, requires_grad=True).to(device)\n",
    "grad_y = torch.rand(100, 500).to(device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True) as prof:\n",
    "    y = tropical2(x, a)\n",
    "\n",
    "print(prof.key_averages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch200cu118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
