{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments on FashionMNIST with a standardized setup\n",
    "\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T12:57:18.223951900Z",
     "start_time": "2023-07-25T12:57:15.161896100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.6.0, llvm 15.0.1, commit f1c6fbbd, win, python 3.10.7\n",
      "[Taichi] Starting on arch=cuda\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "from IPython import display\n",
    "from random import choice, uniform\n",
    "from semitorch import MaxPlus, maxplus_parameters, nonmaxplus_parameters\n",
    "from semitorch import MinPlus, minplus_parameters, nonminplus_parameters\n",
    "from semitorch import TropicalSGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FashionMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T12:57:18.273780300Z",
     "start_time": "2023-07-25T12:57:18.225439600Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 8\n",
    "\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = FashionMNIST(root=\".\", train=True, download=True, transform=transforms_train)\n",
    "testset = FashionMNIST(root=\".\", train=False, download=True, transform=transforms_test)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name: str, layer_norm: bool = False, skip_connections: bool = False,\n",
    "                 k: float = None) -> None:\n",
    "        super().__init__()\n",
    "        self.name = model_name\n",
    "        self.skip_connections = skip_connections\n",
    "\n",
    "        self.stem = nn.Sequential(*list(filter(lambda layer: layer is not None, [\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=4, stride=4),\n",
    "            nn.Flatten(),\n",
    "            nn.LayerNorm(8 * 7 * 7) if layer_norm else None,\n",
    "        ])))\n",
    "\n",
    "        if model_name == \"linear/relu\":\n",
    "            self.backbone_1 = nn.Sequential(\n",
    "                nn.Linear(8 * 7 * 7, 300), nn.ReLU(),\n",
    "                nn.Linear(300, 250), nn.ReLU(),\n",
    "            )\n",
    "            self.backbone_2 = nn.Sequential(\n",
    "                nn.Linear(250 + (8 * 7 * 7 if self.skip_connections else 0), 200), nn.ReLU(),\n",
    "                nn.Linear(200, 150), nn.ReLU(),\n",
    "            )\n",
    "            self.backbone_3 = nn.Sequential(\n",
    "                nn.Linear(150 + (250 if self.skip_connections else 0), 100), nn.ReLU(),\n",
    "                nn.Linear(100, 50), nn.ReLU(),\n",
    "            )\n",
    "        elif model_name == \"linear/maxplus\":\n",
    "            self.backbone_1 = nn.Sequential(\n",
    "                nn.Linear(8 * 7 * 7, 300),\n",
    "                MaxPlus(300, 250, k=k),\n",
    "            )\n",
    "            self.backbone_2 = nn.Sequential(\n",
    "                nn.Linear(250 + (8 * 7 * 7 if self.skip_connections else 0), 200),\n",
    "                MaxPlus(200, 150, k=k),\n",
    "            )\n",
    "            self.backbone_3 = nn.Sequential(\n",
    "                nn.Linear(150 + (250 if self.skip_connections else 0), 100),\n",
    "                MaxPlus(100, 50, k=k),\n",
    "            )\n",
    "        elif model_name == \"linear/minplus\":\n",
    "            self.backbone_1 = nn.Sequential(\n",
    "                nn.Linear(8 * 7 * 7, 300),\n",
    "                MinPlus(300, 250, k=k),\n",
    "            )\n",
    "            self.backbone_2 = nn.Sequential(\n",
    "                nn.Linear(250 + (8 * 7 * 7 if self.skip_connections else 0), 200),\n",
    "                MinPlus(200, 150, k=k),\n",
    "            )\n",
    "            self.backbone_3 = nn.Sequential(\n",
    "                nn.Linear(150 + (250 if self.skip_connections else 0), 100),\n",
    "                MinPlus(100, 50, k=k),\n",
    "            )\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown model ({model_name})\")\n",
    "\n",
    "        self.head = nn.Linear(50, 10, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        input_0 = x\n",
    "        result_0 = self.stem(input_0)\n",
    "\n",
    "        input_1 = result_0\n",
    "        result_1 = self.backbone_1(input_1)\n",
    "\n",
    "        if self.skip_connections:\n",
    "            input_2 = torch.cat((result_1, result_0), dim=-1)\n",
    "        else:\n",
    "            input_2 = result_1\n",
    "        result_2 = self.backbone_2(input_2)\n",
    "\n",
    "        if self.skip_connections:\n",
    "            input_3 = torch.cat((result_2, result_1), dim=-1)\n",
    "        else:\n",
    "            input_3 = result_2\n",
    "        result_3 = self.backbone_3(input_3)\n",
    "\n",
    "        output = self.head(result_3)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T12:57:18.284721200Z",
     "start_time": "2023-07-25T12:57:18.271300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def count_parameters(parameters) -> int:\n",
    "    return sum(p.numel() for p in parameters if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T12:57:18.305686600Z",
     "start_time": "2023-07-25T12:57:18.286209Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T12:57:18.322105200Z",
     "start_time": "2023-07-25T12:57:18.309183600Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(model: nn.Module, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    with torch.no_grad():\n",
    "        yout = model(x)\n",
    "        _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "        return (y.cpu() == prediction).sum().item() / float(y.numel())\n",
    "\n",
    "\n",
    "def test(model: nn.Module, testloader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x = x.to(device)\n",
    "            accs.append(accuracy(model, x, y))\n",
    "\n",
    "    return sum(accs) / len(accs)\n",
    "\n",
    "\n",
    "def confusion_matrix(model: nn.Module, device: str, testloader: DataLoader) -> None:\n",
    "    model.eval()\n",
    "\n",
    "    conf_matrix = torch.zeros(len(testset.classes), len(testset.classes))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "            conf_matrix[y.cpu(), prediction] += 1\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=testset.classes, columns=testset.classes).astype(int)\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=15)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=15)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def train(\n",
    "        model: nn.Module,\n",
    "        device: str,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        schedulers: list[torch.optim.lr_scheduler],\n",
    "        loss: torch.nn.modules.loss,\n",
    "        epochs: int,\n",
    ") -> None:\n",
    "    accs = []  # list of accuracy on the test dataset for every epoch\n",
    "    trainaccs = []  # a list of the accuracies of all the training batches\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=[6, 4])\n",
    "    hdisplay = display.display(\"\", display_id=True)\n",
    "\n",
    "    for _ in trange(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.zero_grad()\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "            print((y.cpu() == prediction))\n",
    "            trainaccs.append((y.cpu() == prediction).sum().item() / float(y.numel()))\n",
    "\n",
    "            l = loss(yout, y.squeeze())\n",
    "            l.backward()\n",
    "            for optimizer in optimizers:\n",
    "                if isinstance(optimizer, TropicalSGD):\n",
    "                    optimizer.step(input_tensor=x.cpu())\n",
    "                else:\n",
    "                    optimizer.step()\n",
    "\n",
    "            for scheduler in schedulers:\n",
    "                scheduler.step()\n",
    "\n",
    "        accs.append(test(model, testloader))\n",
    "\n",
    "        ax.clear()\n",
    "        ax.set_xlim(0, epochs)\n",
    "        ax.set_ylim(-0.02, 1.02)\n",
    "        ax.plot(\n",
    "            np.linspace(0, len(accs), len(trainaccs)),\n",
    "            trainaccs,\n",
    "            \".\",\n",
    "            markersize=1.5,\n",
    "            markerfacecolor=(0, 0, 1, 0.3),\n",
    "        )\n",
    "        ax.plot(np.linspace(1, len(accs), len(accs)), accs)\n",
    "        ax.text(\n",
    "            0.6 * epochs,\n",
    "            0.30,\n",
    "            f\"max test acc = {max(accs):.2%}\",\n",
    "            ha=\"center\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "        hdisplay.update(fig)\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    confusion_matrix(model, device, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def run_model_for_config(config: dict, best_accuracy: float) -> dict:\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    epochs = 20\n",
    "\n",
    "    # Create model\n",
    "    model_name = config[\"model_name\"]\n",
    "    layer_norm = config[\"layer_norm\"]\n",
    "    skip_connections = config[\"skip_connections\"]\n",
    "    k = config[\"k\"]\n",
    "\n",
    "    model = Model(model_name=model_name, layer_norm=layer_norm, skip_connections=skip_connections, k=k).to(device)\n",
    "\n",
    "    # Separate model parameters\n",
    "    if model_name == \"linear/relu\":\n",
    "        linear_params = model.parameters()\n",
    "        semiring_params = nn.ParameterList()\n",
    "    elif model_name == \"linear/maxplus\":\n",
    "        linear_params = nonmaxplus_parameters(model)\n",
    "        semiring_params = maxplus_parameters(model)\n",
    "    elif model_name == \"linear/minplus\":\n",
    "        linear_params = nonminplus_parameters(model)\n",
    "        semiring_params = minplus_parameters(model)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unknown model ({model_name})\")\n",
    "\n",
    "    # Create linear optimizer\n",
    "    linear_lr = config[\"linear_lr\"]\n",
    "    if config[\"linear_optimizer\"] == \"AdamW\":\n",
    "        linear_optimizer = torch.optim.AdamW(linear_params, lr=linear_lr, weight_decay=0.01)\n",
    "    elif config[\"linear_optimizer\"] == \"SGD\":\n",
    "        linear_optimizer = torch.optim.SGD(linear_params, lr=linear_lr)\n",
    "    else:\n",
    "        raise RuntimeError(f'Unknown linear optimizer {config[\"linear_optimizer\"]}')\n",
    "    if config[\"linear_scheduler\"]:\n",
    "        linear_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            linear_optimizer,\n",
    "            max_lr=linear_lr,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=len(trainloader),\n",
    "            epochs=epochs,\n",
    "        )\n",
    "    else:\n",
    "        linear_scheduler = None\n",
    "\n",
    "    # Create semiring optimizer\n",
    "    semiring_lr = config[\"semiring_lr\"]\n",
    "    if config[\"semiring_optimizer\"] is None:\n",
    "        semiring_optimizer = None\n",
    "    elif config[\"semiring_optimizer\"] == \"SGD\":\n",
    "        semiring_optimizer = torch.optim.SGD(semiring_params, lr=semiring_lr)\n",
    "    elif config[\"semiring_optimizer\"] == \"TropicalSGD\":\n",
    "        semiring_optimizer = TropicalSGD(semiring_params, lr=semiring_lr)\n",
    "    else:\n",
    "        raise RuntimeError(f'Unknown semiring optimizer {config[\"semiring_optimizer\"]}')\n",
    "    if config[\"semiring_scheduler\"]:\n",
    "        semiring_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            semiring_optimizer,\n",
    "            max_lr=semiring_lr,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=len(trainloader),\n",
    "            epochs=epochs,\n",
    "        )\n",
    "    else:\n",
    "        semiring_scheduler = None\n",
    "\n",
    "    # Create optimizers and schedulers\n",
    "    optimizers = list(filter(lambda opt: opt is not None, [linear_optimizer, semiring_optimizer]))\n",
    "    schedulers = list(filter(lambda sch: sch is not None, [linear_scheduler, semiring_scheduler]))\n",
    "\n",
    "    report, reported_accuracy, last_reported_accuracy = [], 0, 0\n",
    "    for epoch in range(epochs):\n",
    "        last_reported_accuracy = reported_accuracy\n",
    "\n",
    "        # Feed to training function\n",
    "        reported_accuracy = train_model(\n",
    "            model,\n",
    "            trainloader,\n",
    "            testloader,\n",
    "            optimizers,\n",
    "            schedulers,\n",
    "            loss,\n",
    "        )\n",
    "\n",
    "        # Try some stopping conditions\n",
    "        if ((epoch > 2) and (reported_accuracy < 0.15)) or ((epoch > 5) and (reported_accuracy < best_accuracy / 2)):\n",
    "            # Bad trial\n",
    "            return {\"accuracy\": reported_accuracy, \"config\": config}\n",
    "\n",
    "        if (epoch > 2) and (abs(last_reported_accuracy - reported_accuracy) < 1e-6):\n",
    "            # Run is done, no sense to train it any further\n",
    "            break  # Break for-loop to report\n",
    "\n",
    "    return {\"accuracy\": reported_accuracy, \"config\": config}\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        schedulers: list[torch.optim.lr_scheduler],\n",
    "        loss: torch.nn.modules.loss,\n",
    ") -> float:\n",
    "    model.train()\n",
    "\n",
    "    for x, y in trainloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        l = loss(model(x), y.squeeze())\n",
    "        l.backward()\n",
    "\n",
    "        for optimizer in optimizers:\n",
    "            if isinstance(optimizer, TropicalSGD):\n",
    "                optimizer.step(input_tensor=x.cpu())\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "        for scheduler in schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return test(model, testloader)\n",
    "\n",
    "\n",
    "def run_random_search_for_config(config: dict) -> dict:\n",
    "    best_accuracy, best_config, step_size = 0, None, 0.1\n",
    "    bad_step_counter, good_step_counter = 0, 0\n",
    "    for num_trial in range(100):\n",
    "        result = run_model_for_config(config, best_accuracy=best_accuracy)\n",
    "\n",
    "        if result[\"accuracy\"] > best_accuracy:\n",
    "            bad_step_counter = 0\n",
    "            good_step_counter += 1\n",
    "\n",
    "            best_accuracy, best_config = result[\"accuracy\"], config\n",
    "        else:\n",
    "            bad_step_counter += 1\n",
    "            good_step_counter = 0\n",
    "\n",
    "        if bad_step_counter > 10:\n",
    "            break  # Terminate run, likely no better accuracy possible\n",
    "\n",
    "        config, step_size = adaptive_step_update_config(\n",
    "            config=config,\n",
    "            step_size=step_size,\n",
    "            bad_step_counter=bad_step_counter,\n",
    "            good_step_counter=good_step_counter,\n",
    "        )\n",
    "\n",
    "        if step_size < 1e-2:\n",
    "            # Step size too small to make any impact, terminate run\n",
    "            break\n",
    "\n",
    "    return {\"accuracy\": best_accuracy, \"config\": best_config}\n",
    "\n",
    "\n",
    "def adaptive_step_update_config(\n",
    "        config: dict,\n",
    "        step_size: float,\n",
    "        bad_step_counter: int,\n",
    "        good_step_counter: int,\n",
    ") -> tuple[dict, float]:\n",
    "    # Update step_size\n",
    "    if bad_step_counter > 1:\n",
    "        step_size /= 2\n",
    "    if good_step_counter > 1:\n",
    "        step_size *= 2\n",
    "\n",
    "    # Update config values\n",
    "    if config[\"k\"] is not None:\n",
    "        config[\"k\"] = choice([\n",
    "            config[\"k\"] * (1 - step_size),\n",
    "            config[\"k\"] * (1 + step_size),\n",
    "        ])\n",
    "    config[\"linear_lr\"] = choice([\n",
    "        config[\"linear_lr\"] * (1 - step_size),\n",
    "        config[\"linear_lr\"] * (1 + step_size),\n",
    "    ])\n",
    "    if config[\"semiring_lr\"] is not None:\n",
    "        config[\"semiring_lr\"] = choice([\n",
    "            config[\"semiring_lr\"] * (1 - step_size),\n",
    "            config[\"semiring_lr\"] * (1 + step_size),\n",
    "        ])\n",
    "\n",
    "    return config, step_size\n",
    "\n",
    "\n",
    "def find_best_model_for(config: dict):\n",
    "    current_config, results = deepcopy(config), []\n",
    "    for layer_norm in config[\"layer_norm\"]:\n",
    "        current_config[\"layer_norm\"] = layer_norm\n",
    "        for skip_connections in config[\"skip_connections\"]:\n",
    "            current_config[\"skip_connections\"] = skip_connections\n",
    "            for linear_optimizer in config[\"linear_optimizer\"]:\n",
    "                current_config[\"linear_optimizer\"] = linear_optimizer\n",
    "                for linear_scheduler in config[\"linear_scheduler\"]:\n",
    "                    current_config[\"linear_scheduler\"] = linear_scheduler\n",
    "                    if config[\"semiring_optimizer\"] is not None:\n",
    "                        for semiring_optimizer in config[\"semiring_optimizer\"]:\n",
    "                            current_config[\"semiring_optimizer\"] = semiring_optimizer\n",
    "                            for semiring_scheduler in config[\"semiring_scheduler\"]:\n",
    "                                current_config[\"semiring_scheduler\"] = semiring_scheduler\n",
    "\n",
    "                                print(f\"Starting semiring run for config {current_config}\")\n",
    "                                results.append(run_random_search_for_config(current_config))\n",
    "\n",
    "                    else:\n",
    "                        print(f\"Starting linear run for config {current_config}\")\n",
    "                        results.append(run_random_search_for_config(current_config))\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda dictionary: dictionary[\"accuracy\"], reverse=True)\n",
    "    best_result = sorted_results[0]\n",
    "    print(f'Best trial config with accuracy of {best_result[\"accuracy\"]}: {best_result[\"config\"]}')\n",
    "    print(f\"-----------------\\n{sorted_results}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T12:57:18.351502600Z",
     "start_time": "2023-07-25T12:57:18.318125400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Default Linear Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting linear run for config {'model_name': 'linear/relu', 'layer_norm': True, 'skip_connections': True, 'k': None, 'linear_optimizer': 'AdamW', 'linear_scheduler': True, 'linear_lr': 0.0003624739850217251, 'semiring_lr': None, 'semiring_optimizer': None, 'semiring_scheduler': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/relu\",\n",
    "    \"layer_norm\": [True, False],\n",
    "    \"skip_connections\": [True, False],\n",
    "    \"k\": None,\n",
    "    \"linear_optimizer\": [\"AdamW\", \"SGD\"],\n",
    "    \"linear_scheduler\": [True, False],\n",
    "    \"linear_lr\": 10 ** uniform(-6, -2),\n",
    "    \"semiring_lr\": None,\n",
    "    \"semiring_optimizer\": None,\n",
    "    \"semiring_scheduler\": None,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-25T12:59:09.007987300Z",
     "start_time": "2023-07-25T12:57:18.348515600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best linear model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_linear_model = Model(model_name=\"linear/relu\", layer_norm=layer_norm, skip_connections=skip_connections).to(device)\n",
    "print(f\"{best_linear_model.name} model has {count_parameters(best_linear_model.parameters())} trainable parameters\")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epochs = 20\n",
    "\n",
    "best_linear_optimizer = torch.optim.AdamW(best_linear_model.parameters(), lr=lr1, weight_decay=0.01)\n",
    "best_linear_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    best_linear_optimizer,\n",
    "    max_lr=lr1,\n",
    "    anneal_strategy=\"linear\",\n",
    "    pct_start=0.3,\n",
    "    three_phase=True,\n",
    "    final_div_factor=1000.0,\n",
    "    div_factor=10.0,\n",
    "    steps_per_epoch=len(trainloader),\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "train(\n",
    "    best_linear_model,\n",
    "    device,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    [best_linear_optimizer],\n",
    "    [best_linear_scheduler],\n",
    "    loss,\n",
    "    epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tropical models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MaxPlus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/maxplus\",\n",
    "    \"layer_norm\": [True, False],\n",
    "    \"skip_connections\": [True, False],\n",
    "    \"k\": uniform(-3, -1),\n",
    "    \"linear_optimizer\": [\"AdamW\", \"SGD\"],\n",
    "    \"linear_scheduler\": [True, False],\n",
    "    \"linear_lr\": 10 ** uniform(-6, -2),\n",
    "    \"semiring_lr\": 10 ** uniform(-6, -2),\n",
    "    \"semiring_optimizer\": [\"SGD\", \"TropicalSGD\"],\n",
    "    \"semiring_scheduler\": [True, False],\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best MaxPlus model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_maxplus_model = Model(\"linear/maxplus\").to(device)\n",
    "\n",
    "print(f\"{best_maxplus_model.name} model has {count_parameters(best_maxplus_model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(nonmaxplus_parameters(best_maxplus_model))} are linear \"\n",
    "      f\"and {count_parameters(maxplus_parameters(best_maxplus_model))} are semiring related\")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epochs = 20\n",
    "\n",
    "best_maxplus_linear_optimizer = torch.optim.SGD(nonmaxplus_parameters(best_maxplus_model), lr=lr1)\n",
    "best_maxplus_linear_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    best_maxplus_linear_optimizer,\n",
    "    max_lr=lr1,\n",
    "    anneal_strategy=\"linear\",\n",
    "    pct_start=0.3,\n",
    "    three_phase=True,\n",
    "    final_div_factor=1000.0,\n",
    "    div_factor=10.0,\n",
    "    steps_per_epoch=len(trainloader),\n",
    "    epochs=epochs,\n",
    ")\n",
    "best_maxplus_semiring_optimizer = torch.optim.SGD(maxplus_parameters(best_maxplus_model), lr=lr2)\n",
    "\n",
    "best_maxplus_optimizers = [best_maxplus_linear_optimizer, best_maxplus_semiring_optimizer]\n",
    "best_maxplus_schedulers = [best_maxplus_linear_scheduler]\n",
    "\n",
    "train(\n",
    "    best_maxplus_model,\n",
    "    device,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    best_maxplus_optimizers,\n",
    "    best_maxplus_schedulers,\n",
    "    loss,\n",
    "    epochs,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MinPlus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/minplus\",\n",
    "    \"layer_norm\": [True, False],\n",
    "    \"skip_connections\": [True, False],\n",
    "    \"k\": uniform(1, 3),\n",
    "    \"linear_optimizer\": [\"AdamW\", \"SGD\"],\n",
    "    \"linear_scheduler\": [True, False],\n",
    "    \"linear_lr\": 10 ** uniform(-6, -2),\n",
    "    \"semiring_lr\": 10 ** uniform(-6, -2),\n",
    "    \"semiring_optimizer\": [\"SGD\", \"TropicalSGD\"],\n",
    "    \"semiring_scheduler\": [True, False],\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best MinPlus model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_minplus_model = Model(\"linear/minplus\").to(device)\n",
    "\n",
    "print(f\"{best_minplus_model.name} model has {count_parameters(best_minplus_model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(nonminplus_parameters(best_minplus_model))} are linear \"\n",
    "      f\"and {count_parameters(minplus_parameters(best_minplus_model))} are semiring related\")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "epochs = 20\n",
    "\n",
    "best_minplus_linear_optimizer = torch.optim.SGD(nonminplus_parameters(best_minplus_model), lr=lr1)\n",
    "best_minplus_linear_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    best_minplus_linear_optimizer,\n",
    "    max_lr=lr1,\n",
    "    anneal_strategy=\"linear\",\n",
    "    pct_start=0.3,\n",
    "    three_phase=True,\n",
    "    final_div_factor=1000.0,\n",
    "    div_factor=10.0,\n",
    "    steps_per_epoch=len(trainloader),\n",
    "    epochs=epochs,\n",
    ")\n",
    "best_minplus_semiring_optimizer = torch.optim.SGD(minplus_parameters(best_minplus_model), lr=lr2)\n",
    "\n",
    "best_minplus_optimizers = [best_minplus_linear_optimizer, best_minplus_semiring_optimizer]\n",
    "best_minplus_schedulers = [best_minplus_linear_scheduler]\n",
    "\n",
    "train(\n",
    "    best_maxplus_model,\n",
    "    device,\n",
    "    trainloader,\n",
    "    testloader,\n",
    "    best_minplus_optimizers,\n",
    "    best_minplus_schedulers,\n",
    "    loss,\n",
    "    epochs,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
