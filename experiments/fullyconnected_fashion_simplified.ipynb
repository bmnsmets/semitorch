{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments on FashionMNIST with a standardized minimized setup\n",
    "\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T16:31:55.352560700Z",
     "start_time": "2023-09-10T16:31:55.223714Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "from IPython import display\n",
    "from random import uniform\n",
    "from semitorch import (\n",
    "    MaxPlus, maxplus_parameters, nonmaxplus_parameters,\n",
    "    MinPlus, minplus_parameters, nonminplus_parameters,\n",
    "    SemiLog, semilog_parameters, nonsemilog_parameters,\n",
    ")\n",
    "from statistics import quantiles\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FashionMNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T16:31:55.393512700Z",
     "start_time": "2023-09-10T16:31:55.244507600Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 8\n",
    "\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fmnist_trainset = FashionMNIST(root=\".\", train=True, download=True, transform=transforms_train)\n",
    "fmnist_testset = FashionMNIST(root=\".\", train=False, download=True, transform=transforms_test)\n",
    "\n",
    "fmnist_trainloader = DataLoader(fmnist_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "fmnist_testloader = DataLoader(fmnist_testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            mu: float = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.name = model_name\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=4, stride=4),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        if model_name == \"linear/relu\":\n",
    "            self.backbone_1 = nn.Sequential(\n",
    "                nn.Linear(8 * 7 * 7, 300), nn.ReLU(),\n",
    "                nn.Linear(300, 250), nn.ReLU(),\n",
    "            )\n",
    "            self.backbone_2 = nn.Sequential(\n",
    "                nn.Linear(250, 200), nn.ReLU(),\n",
    "                nn.Linear(200, 150), nn.ReLU(),\n",
    "            )\n",
    "            self.backbone_3 = nn.Sequential(\n",
    "                nn.Linear(150, 100), nn.ReLU(),\n",
    "                nn.Linear(100, 50), nn.ReLU(),\n",
    "            )\n",
    "        elif model_name == \"linear/maxplus\":\n",
    "            self.backbone_1 = nn.Sequential(\n",
    "                nn.Linear(8 * 7 * 7, 300),\n",
    "                MaxPlus(300, 250),\n",
    "            )\n",
    "            self.backbone_2 = nn.Sequential(\n",
    "                nn.Linear(250, 200),\n",
    "                MaxPlus(200, 150),\n",
    "            )\n",
    "            self.backbone_3 = nn.Sequential(\n",
    "                nn.Linear(150, 100),\n",
    "                MaxPlus(100, 50),\n",
    "            )\n",
    "        elif model_name == \"linear/minplus\":\n",
    "            self.backbone_1 = nn.Sequential(\n",
    "                nn.Linear(8 * 7 * 7, 300),\n",
    "                MinPlus(300, 250),\n",
    "            )\n",
    "            self.backbone_2 = nn.Sequential(\n",
    "                nn.Linear(250, 200),\n",
    "                MinPlus(200, 150),\n",
    "            )\n",
    "            self.backbone_3 = nn.Sequential(\n",
    "                nn.Linear(150, 100),\n",
    "                MinPlus(100, 50),\n",
    "            )\n",
    "        elif model_name == \"linear/log\":\n",
    "            self.backbone_1 = nn.Sequential(\n",
    "                nn.Linear(8 * 7 * 7, 300),\n",
    "                SemiLog(300, 250, mu=mu),\n",
    "            )\n",
    "            self.backbone_2 = nn.Sequential(\n",
    "                nn.Linear(250, 200),\n",
    "                SemiLog(200, 150, mu=mu),\n",
    "            )\n",
    "            self.backbone_3 = nn.Sequential(\n",
    "                nn.Linear(150, 100),\n",
    "                SemiLog(100, 50, mu=mu),\n",
    "            )\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown model ({model_name})\")\n",
    "\n",
    "        self.head = nn.Linear(50, 10, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        input_0 = x\n",
    "        result_0 = self.stem(input_0)\n",
    "\n",
    "        input_1 = result_0\n",
    "        result_1 = self.backbone_1(input_1)\n",
    "\n",
    "        input_2 = result_1\n",
    "        result_2 = self.backbone_2(input_2)\n",
    "\n",
    "        input_3 = result_2\n",
    "        result_3 = self.backbone_3(input_3)\n",
    "\n",
    "        output = self.head(result_3)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T16:31:55.396489200Z",
     "start_time": "2023-09-10T16:31:55.287580800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def count_parameters(parameters) -> int:\n",
    "    return sum(p.numel() for p in parameters if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T16:31:55.396985200Z",
     "start_time": "2023-09-10T16:31:55.303742300Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-10T16:31:55.397480300Z",
     "start_time": "2023-09-10T16:31:55.318669100Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(model: nn.Module, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    with torch.no_grad():\n",
    "        yout = model(x)\n",
    "        _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "        return (y.cpu() == prediction).sum().item() / float(y.numel())\n",
    "\n",
    "\n",
    "def test(model: nn.Module, testloader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x = x.to(device)\n",
    "            accs.append(accuracy(model, x, y))\n",
    "\n",
    "    return sum(accs) / len(accs)\n",
    "\n",
    "\n",
    "def confusion_matrix(model: nn.Module, testloader: DataLoader) -> None:\n",
    "    model.eval()\n",
    "\n",
    "    conf_matrix = torch.zeros(len(fmnist_testset.classes), len(fmnist_testset.classes))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "            conf_matrix[y.cpu(), prediction] += 1\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=fmnist_testset.classes, columns=fmnist_testset.classes).astype(int)\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=15)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=15)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def train(\n",
    "        model: nn.Module,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        loss: torch.nn.modules.loss,\n",
    "        epochs: int,\n",
    "        statistics_mode: bool = False  # If True: (return max acc and do not generate output)\n",
    ") -> None | float:\n",
    "    accs = []  # list of accuracy on the test dataset for every epoch\n",
    "    trainaccs = []  # a list of the accuracies of all the training batches\n",
    "\n",
    "    if not statistics_mode:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[6, 4])\n",
    "        hdisplay = display.display(\"\", display_id=True)\n",
    "\n",
    "    for _ in trange(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.zero_grad()\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "            trainaccs.append((y.cpu() == prediction).sum().item() / float(y.numel()))\n",
    "\n",
    "            l = loss(yout, y.squeeze())\n",
    "            l.backward()\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.step()\n",
    "\n",
    "        accs.append(test(model, testloader))\n",
    "\n",
    "        if not statistics_mode:\n",
    "            ax.clear()\n",
    "            ax.set_xlim(0, epochs)\n",
    "            ax.set_ylim(-0.02, 1.02)\n",
    "            ax.plot(\n",
    "                np.linspace(0, len(accs), len(trainaccs)),\n",
    "                trainaccs,\n",
    "                \".\",\n",
    "                markersize=1.5,\n",
    "                markerfacecolor=(0, 0, 1, 0.3),\n",
    "            )\n",
    "            ax.plot(np.linspace(1, len(accs), len(accs)), accs)\n",
    "            ax.text(\n",
    "                0.6 * epochs,\n",
    "                0.30,\n",
    "                f\"max test acc = {max(accs):.2%}\",\n",
    "                ha=\"center\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "            hdisplay.update(fig)\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    if not statistics_mode:\n",
    "        confusion_matrix(model, testloader)\n",
    "        \n",
    "    if statistics_mode:\n",
    "        return max(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def run_model_for_config(config: dict, best_accuracy: float) -> dict:\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    epochs = 20\n",
    "\n",
    "    # Create model\n",
    "    model_name = config[\"model_name\"]\n",
    "    linear_lr = config[\"linear_lr\"]\n",
    "    semiring_lr = config[\"semiring_lr\"]\n",
    "    mu = config[\"mu\"]\n",
    "\n",
    "    model = Model(model_name=model_name, mu=mu).to(device)\n",
    "\n",
    "    # Separate model parameters\n",
    "    if model_name == \"linear/relu\":\n",
    "        linear_params = model.parameters()\n",
    "        semiring_params = nn.ParameterList()\n",
    "    elif model_name == \"linear/maxplus\":\n",
    "        linear_params = nonmaxplus_parameters(model)\n",
    "        semiring_params = maxplus_parameters(model)\n",
    "    elif model_name == \"linear/minplus\":\n",
    "        linear_params = nonminplus_parameters(model)\n",
    "        semiring_params = minplus_parameters(model)\n",
    "    elif model_name == \"linear/log\":\n",
    "        linear_params = nonsemilog_parameters(model)\n",
    "        semiring_params = semilog_parameters(model)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unknown model ({model_name})\")\n",
    "\n",
    "    # Create linear optimizer\n",
    "    linear_optimizer = torch.optim.AdamW(linear_params, lr=linear_lr)\n",
    "\n",
    "    # Create semiring optimizer\n",
    "    if model_name == \"linear/relu\":\n",
    "        semiring_optimizer = None\n",
    "    else:\n",
    "        semiring_optimizer = torch.optim.AdamW(semiring_params, lr=semiring_lr)\n",
    "\n",
    "    # Create optimizers\n",
    "    optimizers = list(filter(lambda opt: opt is not None, [linear_optimizer, semiring_optimizer]))\n",
    "\n",
    "    reported_accuracy, last_reported_accuracy = [[], []], [[], []]\n",
    "    for attempt in range(2):  # Run twice to detect and filter out anomalies\n",
    "        reported_accuracy[attempt], last_reported_accuracy[attempt] = 0, 0\n",
    "        for epoch in range(epochs):\n",
    "            last_reported_accuracy[attempt] = reported_accuracy[attempt]\n",
    "    \n",
    "            # Feed to training function\n",
    "            reported_accuracy[attempt] = train_model(\n",
    "                model,\n",
    "                fmnist_trainloader,\n",
    "                fmnist_testloader,\n",
    "                optimizers,\n",
    "                loss,\n",
    "            )\n",
    "    \n",
    "            # Try some stopping conditions\n",
    "            if (((epoch > 2) and (reported_accuracy[attempt] < 0.15))\n",
    "                    or ((epoch > 5) and (reported_accuracy[attempt] < best_accuracy / 2))\n",
    "                    or ((epoch > 2) and (abs(last_reported_accuracy[attempt] - reported_accuracy[attempt]) < 1e-6))):\n",
    "                # Run is done, no sense to train it any further\n",
    "                # or bad trial\n",
    "                break  # Break for-loop to report\n",
    "\n",
    "    return {\"accuracy\": min(reported_accuracy), \"config\": config}\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        loss: torch.nn.modules.loss,\n",
    ") -> float:\n",
    "    model.train()\n",
    "\n",
    "    for x, y in trainloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        l = loss(model(x), y.squeeze())\n",
    "        l.backward()\n",
    "\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return test(model, testloader)\n",
    "\n",
    "\n",
    "def run_random_search_for_config(config: dict) -> dict:\n",
    "    best_accuracy, best_config, current_config = 0, deepcopy(config), deepcopy(config)\n",
    "    step_size, bad_step_counter, good_step_counter = 0.1, 0, 0\n",
    "    for num_trial in range(100):\n",
    "        result = run_model_for_config(current_config, best_accuracy=best_accuracy)\n",
    "\n",
    "        if result[\"accuracy\"] > best_accuracy:\n",
    "            bad_step_counter = 0\n",
    "            good_step_counter += 1\n",
    "\n",
    "            best_accuracy, best_config = result[\"accuracy\"], deepcopy(current_config)\n",
    "        else:\n",
    "            bad_step_counter += 1\n",
    "            good_step_counter = 0\n",
    "\n",
    "        if bad_step_counter > 10:\n",
    "            break  # Terminate run, likely no better accuracy possible\n",
    "\n",
    "        current_config, step_size, bad_step_counter, good_step_counter = adaptive_step_update_config(\n",
    "            config=deepcopy(best_config),\n",
    "            step_size=step_size,\n",
    "            bad_step_counter=bad_step_counter,\n",
    "            good_step_counter=good_step_counter,\n",
    "        )\n",
    "\n",
    "        if step_size < 1e-2:\n",
    "            # Step size too small to make any impact, terminate run\n",
    "            break\n",
    "\n",
    "    return {\"accuracy\": best_accuracy, \"config\": best_config}\n",
    "\n",
    "\n",
    "def adaptive_step_update_config(\n",
    "        config: dict,\n",
    "        step_size: float,\n",
    "        bad_step_counter: int,\n",
    "        good_step_counter: int,\n",
    ") -> tuple[dict, float, int, int]:\n",
    "    # Update step_size\n",
    "    if bad_step_counter > 2:\n",
    "        step_size /= 2\n",
    "        bad_step_counter = 0\n",
    "    if (good_step_counter > 2) and (step_size < 0.5):\n",
    "        step_size *= 2\n",
    "        good_step_counter = 0\n",
    "\n",
    "    # Update config values\n",
    "    config[\"linear_lr\"] = uniform(\n",
    "        config[\"linear_lr\"] * (1 - step_size),\n",
    "        config[\"linear_lr\"] * (1 + step_size),\n",
    "    )\n",
    "    if config[\"model_name\"] != \"linear/relu\":\n",
    "        config[\"semiring_lr\"] = uniform(\n",
    "            config[\"semiring_lr\"] * (1 - step_size),\n",
    "            config[\"semiring_lr\"] * (1 + step_size),\n",
    "        )\n",
    "\n",
    "    return config, step_size, bad_step_counter, good_step_counter\n",
    "\n",
    "\n",
    "def find_best_model_for(config: dict) -> None:\n",
    "    current_config, results = deepcopy(config), []\n",
    "\n",
    "    print(f\"Starting run for config {current_config}\")\n",
    "    result = run_random_search_for_config(current_config)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-10T16:31:55.398472800Z",
     "start_time": "2023-09-10T16:31:55.342042700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8892578125, 'config': {'model_name': 'linear/relu', 'linear_lr': 0.0010659631874881759, 'semiring_lr': None, 'mu': None}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/relu\",\n",
    "    \"linear_lr\": 10 ** uniform(-3, -1),\n",
    "    \"semiring_lr\": None,\n",
    "    \"mu\": None,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_linear_model = Model(model_name=\"linear/relu\").to(device)\n",
    "print(f\"{best_linear_model.name} model has {count_parameters(best_linear_model.parameters())} trainable parameters\")\n",
    "\n",
    "best_linear_optimizer = torch.optim.AdamW(best_linear_model.parameters(), lr=0.0010659631874881759)\n",
    "\n",
    "train(\n",
    "    best_linear_model,\n",
    "    fmnist_trainloader,\n",
    "    fmnist_testloader,\n",
    "    [best_linear_optimizer],\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_linear_model_accs = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    best_linear_model = Model(model_name=\"linear/relu\").to(device)\n",
    "    \n",
    "    best_linear_optimizer = torch.optim.SGD(best_linear_model.parameters(), lr=0.0010659631874881759)\n",
    "    \n",
    "    best_linear_model_accs.append(train(\n",
    "        best_linear_model,\n",
    "        fmnist_trainloader,\n",
    "        fmnist_testloader,\n",
    "        [best_linear_optimizer],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "print(min(best_linear_model_accs))\n",
    "print(quantiles(best_linear_model_accs))\n",
    "print(max(best_linear_model_accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MaxPlus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.87861328125, 'config': {'model_name': 'linear/maxplus', 'linear_lr': 0.0019006891102592055, 'semiring_lr': 0.004447233716116792, 'mu': None}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/maxplus\",\n",
    "    \"linear_lr\": 10 ** uniform(-3, -2),\n",
    "    \"semiring_lr\": 10 ** uniform(-3, -2),\n",
    "    \"mu\": None,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_maxplus_model = Model(\"linear/maxplus\").to(device)\n",
    "\n",
    "print(f\"{best_maxplus_model.name} model has {count_parameters(best_maxplus_model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(nonmaxplus_parameters(best_maxplus_model))} are linear \"\n",
    "      f\"and {count_parameters(maxplus_parameters(best_maxplus_model))} are semiring related\")\n",
    "\n",
    "best_maxplus_linear_optimizer = torch.optim.AdamW(nonmaxplus_parameters(best_maxplus_model), lr=0.0019006891102592055)\n",
    "best_maxplus_semiring_optimizer = torch.optim.AdamW(maxplus_parameters(best_maxplus_model), lr=0.004447233716116792)\n",
    "\n",
    "best_maxplus_optimizers = [best_maxplus_linear_optimizer, best_maxplus_semiring_optimizer]\n",
    "\n",
    "train(\n",
    "    best_maxplus_model,\n",
    "    fmnist_trainloader,\n",
    "    fmnist_testloader,\n",
    "    best_maxplus_optimizers,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_maxplus_model_accs = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    best_maxplus_model = Model(\"linear/maxplus\").to(device)\n",
    "\n",
    "    best_maxplus_linear_optimizer = torch.optim.AdamW(nonmaxplus_parameters(best_maxplus_model), lr=0.0019006891102592055)\n",
    "    best_maxplus_semiring_optimizer = torch.optim.AdamW(maxplus_parameters(best_maxplus_model), lr=0.004447233716116792)\n",
    "    \n",
    "    best_maxplus_optimizers = [best_maxplus_linear_optimizer, best_maxplus_semiring_optimizer]\n",
    "    \n",
    "    best_maxplus_model_accs.append(train(\n",
    "        best_maxplus_model,\n",
    "        fmnist_trainloader,\n",
    "        fmnist_testloader,\n",
    "        best_maxplus_optimizers,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "print(min(best_maxplus_model_accs))\n",
    "print(quantiles(best_maxplus_model_accs))\n",
    "print(max(best_maxplus_model_accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MinPlus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/minplus\",\n",
    "    \"linear_lr\": 10 ** uniform(-3, -1),\n",
    "    \"semiring_lr\": 10 ** uniform(-3, -1),\n",
    "    \"mu\": None,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_minplus_model = Model(\"linear/minplus\").to(device)\n",
    "\n",
    "print(f\"{best_minplus_model.name} model has {count_parameters(best_minplus_model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(nonminplus_parameters(best_minplus_model))} are linear \"\n",
    "      f\"and {count_parameters(minplus_parameters(best_minplus_model))} are semiring related\")\n",
    "\n",
    "best_minplus_linear_optimizer = torch.optim.AdamW(nonminplus_parameters(best_minplus_model), lr=0.018974365406776775)\n",
    "best_minplus_semiring_optimizer = torch.optim.AdamW(minplus_parameters(best_minplus_model), lr=0.006414301068194281)\n",
    "\n",
    "best_minplus_optimizers = [best_minplus_linear_optimizer, best_minplus_semiring_optimizer]\n",
    "\n",
    "train(\n",
    "    best_minplus_model,\n",
    "    fmnist_trainloader,\n",
    "    fmnist_testloader,\n",
    "    best_minplus_optimizers,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_minplus_model_accs = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    best_minplus_model = Model(\"linear/minplus\").to(device)\n",
    "\n",
    "    best_minplus_linear_optimizer = torch.optim.AdamW(nonminplus_parameters(best_minplus_model), lr=0.018974365406776775)\n",
    "    best_minplus_semiring_optimizer = torch.optim.AdamW(minplus_parameters(best_minplus_model), lr=0.006414301068194281)\n",
    "    \n",
    "    best_minplus_optimizers = [best_minplus_linear_optimizer, best_minplus_semiring_optimizer]\n",
    "    \n",
    "    best_minplus_model_accs.append(train(\n",
    "        best_minplus_model,\n",
    "        fmnist_trainloader,\n",
    "        fmnist_testloader,\n",
    "        best_minplus_optimizers,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "print(min(best_minplus_model_accs))\n",
    "print(quantiles(best_minplus_model_accs))\n",
    "print(max(best_minplus_model_accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Log semiring"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8748046875, 'config': {'model_name': 'linear/log', 'linear_lr': 0.0017738002149691953, 'semiring_lr': 0.010464350538565372, 'mu': 1.0}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/log\",\n",
    "    \"linear_lr\": 10 ** uniform(-3, -1),\n",
    "    \"semiring_lr\": 10 ** uniform(-3, -1),\n",
    "    \"mu\": 1.0,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"model_name\": \"linear/log\",\n",
    "    \"linear_lr\": 10 ** uniform(-3, -1),\n",
    "    \"semiring_lr\": 10 ** uniform(-3, -1),\n",
    "    \"mu\": -1.0,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_semilog_model = Model(\"linear/log\", mu=-1.0).to(device)\n",
    "\n",
    "print(f\"{best_semilog_model.name} model has {count_parameters(best_semilog_model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(nonsemilog_parameters(best_semilog_model))} are linear \"\n",
    "      f\"and {count_parameters(semilog_parameters(best_semilog_model))} are semiring related\")\n",
    "\n",
    "best_semilog_linear_optimizer = torch.optim.AdamW(nonsemilog_parameters(best_semilog_model), lr=0.0031251852421539513)\n",
    "best_semilog_semiring_optimizer = torch.optim.AdamW(semilog_parameters(best_semilog_model), lr=0.0340559406041131)\n",
    "\n",
    "best_semilog_optimizers = [best_semilog_linear_optimizer, best_semilog_semiring_optimizer]\n",
    "\n",
    "train(\n",
    "    best_semilog_model,\n",
    "    fmnist_trainloader,\n",
    "    fmnist_testloader,\n",
    "    best_semilog_optimizers,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_semilog_model_accs = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    best_semilog_model = Model(\"linear/log\", mu=-1.0).to(device)\n",
    "\n",
    "    best_semilog_linear_optimizer = torch.optim.AdamW(nonsemilog_parameters(best_semilog_model), lr=0.0031251852421539513)\n",
    "    best_semilog_semiring_optimizer = torch.optim.AdamW(semilog_parameters(best_semilog_model), lr=0.0340559406041131)\n",
    "    \n",
    "    best_semilog_optimizers = [best_semilog_linear_optimizer, best_semilog_semiring_optimizer]\n",
    "    \n",
    "    best_semilog_model_accs.append(train(\n",
    "        best_semilog_model,\n",
    "        fmnist_trainloader,\n",
    "        fmnist_testloader,\n",
    "        best_semilog_optimizers,\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "print(min(best_semilog_model_accs))\n",
    "print(quantiles(best_semilog_model_accs))\n",
    "print(max(best_semilog_model_accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
