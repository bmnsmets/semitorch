{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments\n",
    "\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:09.362254700Z",
     "start_time": "2023-11-14T20:39:05.874450700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.6.0, llvm 15.0.1, commit f1c6fbbd, win, python 3.10.7\n",
      "[Taichi] Starting on arch=cuda\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "from IPython import display\n",
    "from random import uniform\n",
    "from semitorch import (\n",
    "    ClampAdamW, ClampSGD,\n",
    "    Lukasiewicz, lukasiewicz_parameters,\n",
    "    Viterbi, viterbi_parameters,\n",
    "    IrisDatasetTransformer, HeartDiseaseDatasetTransformer,\n",
    "    CirclesDatasetTransformer, RingsDatasetTransformer,\n",
    "    SpheresDatasetTransformer,\n",
    ")\n",
    "from statistics import quantiles\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def split_dataset(dataset: torch.utils.data.Dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iris data\n",
    "[https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:09.421865800Z",
     "start_time": "2023-11-14T20:39:09.363742500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset: input features = 4, classes = 3, samples = 150\n"
     ]
    }
   ],
   "source": [
    "iris_df = pd.read_csv(\n",
    "    os.path.join(data_path, \"iris.csv\"), index_col=0, dtype={\"Species\": \"string\"}\n",
    ")\n",
    "iris_x = torch.Tensor(iris_df.iloc[:, [0, 1, 2, 3]].to_numpy())\n",
    "iris_x = IrisDatasetTransformer(data_to_transform=iris_x, device=device).transform()\n",
    "\n",
    "iris_y = (\n",
    "    iris_df[\"Species\"]\n",
    "    .map({\n",
    "        \"Iris-setosa\": 0,\n",
    "        \"Iris-versicolor\": 1,\n",
    "        \"Iris-virginica\": 2,\n",
    "    }).to_numpy()\n",
    ")\n",
    "iris_y = torch.Tensor(iris_y).to(torch.int64).to(device)\n",
    "print(f\"Iris dataset: input features = {iris_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(iris_y).shape[0]}, \"\n",
    "      f\"samples = {len(iris_y)}\")\n",
    "\n",
    "iris_train, iris_test = split_dataset(torch.utils.data.TensorDataset(iris_x, iris_y))\n",
    "\n",
    "iris_train_loader = DataLoader(iris_train, batch_size=8, shuffle=True)\n",
    "iris_test_loader = DataLoader(iris_test, batch_size=len(iris_test), shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load heart disease data\n",
    "\n",
    "[https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:15.344700800Z",
     "start_time": "2023-11-14T20:39:15.297532300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart disease dataset: input features = 30, classes = 2, samples = 303\n"
     ]
    }
   ],
   "source": [
    "heart_df = pd.read_csv(os.path.join(data_path, \"heart.csv\"))\n",
    "heart_x = torch.Tensor(heart_df.iloc[:, range(13)].to_numpy()).to(torch.float32)\n",
    "heart_x = HeartDiseaseDatasetTransformer(data_to_transform=heart_x, device=device).transform()\n",
    "heart_y = torch.Tensor(heart_df.iloc[:, -1].to_numpy()).to(torch.int64).to(device)\n",
    "\n",
    "print(f\"Heart disease dataset: input features = {heart_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(heart_y).shape[0]}, \"\n",
    "      f\"samples = {len(heart_y)}\")\n",
    "\n",
    "heart_train, heart_test = split_dataset(torch.utils.data.TensorDataset(heart_x, heart_y))\n",
    "heart_train_loader = DataLoader(heart_train, batch_size=32, shuffle=True)\n",
    "heart_test_loader = DataLoader(heart_test, batch_size=len(heart_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Naitzat data\n",
    "\n",
    "[https://github.com/topnn/topnn_framework](https://github.com/topnn/topnn_framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:17.380552900Z",
     "start_time": "2023-11-14T20:39:16.698550700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circles dataset: input features = 2, classes = 2, samples = 15950\n",
      "Rings dataset: input features = 3, classes = 2, samples = 45000\n",
      "Spheres dataset: input features = 3, classes = 2, samples = 37800\n"
     ]
    }
   ],
   "source": [
    "circles_x, circles_y = torch.load(os.path.join(data_path, \"naitzat\", \"circles_type_8.pt\"))\n",
    "circles_x = CirclesDatasetTransformer(data_to_transform=circles_x, device=device).transform()\n",
    "circles_y = torch.squeeze(circles_y)\n",
    "print(f\"Circles dataset: input features = {circles_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(circles_y).shape[0]}, \"\n",
    "      f\"samples = {len(circles_y)}\")\n",
    "circles_train, circles_test = split_dataset(torch.utils.data.TensorDataset(circles_x, circles_y))\n",
    "circles_train_loader = DataLoader(circles_train, batch_size=16, shuffle=True)\n",
    "circles_test_loader = DataLoader(circles_test, batch_size=len(circles_test), shuffle=True)\n",
    "\n",
    "rings_x, rings_y = torch.load(os.path.join(data_path, \"naitzat\", \"rings_9.pt\"))\n",
    "rings_x = RingsDatasetTransformer(data_to_transform=rings_x, device=device).transform()\n",
    "rings_y = torch.squeeze(rings_y)\n",
    "print(f\"Rings dataset: input features = {rings_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(rings_y).shape[0]}, \"\n",
    "      f\"samples = {len(rings_y)}\")\n",
    "rings_train, rings_test = split_dataset(torch.utils.data.TensorDataset(rings_x, rings_y))\n",
    "rings_train_loader = DataLoader(rings_train, batch_size=16, shuffle=True)\n",
    "rings_test_loader = DataLoader(rings_test, batch_size=len(rings_test), shuffle=True)\n",
    "\n",
    "spheres_x, spheres_y = torch.load(os.path.join(data_path, \"naitzat\", \"spheres_9.pt\"))\n",
    "spheres_x = SpheresDatasetTransformer(data_to_transform=spheres_x, device=device).transform()\n",
    "spheres_y = torch.squeeze(spheres_y)\n",
    "print(f\"Spheres dataset: input features = {spheres_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(spheres_y).shape[0]}, \"\n",
    "      f\"samples = {len(spheres_y)}\")\n",
    "spheres_train, spheres_test = split_dataset(torch.utils.data.TensorDataset(spheres_x, spheres_y))\n",
    "spheres_train_loader = DataLoader(spheres_train, batch_size=16, shuffle=True)\n",
    "spheres_test_loader = DataLoader(spheres_test, batch_size=len(spheres_test), shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:19.894498500Z",
     "start_time": "2023-11-14T20:39:19.866280300Z"
    }
   },
   "outputs": [],
   "source": [
    "class IrisModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.name = \"iris\"\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(4, 16)\n",
    "            self.layer2 = Lukasiewicz(16, 16)\n",
    "            self.head = Viterbi(16, 3, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(4, 16)\n",
    "            self.layer2 = Viterbi(16, 16)\n",
    "            self.head = Lukasiewicz(16, 3, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "\n",
    "        return self.head(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class HeartModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.name = \"heart\"\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(30, 16)\n",
    "            self.layer2 = Lukasiewicz(16, 16)\n",
    "            self.layer3 = Viterbi(16, 16)\n",
    "            self.layer4 = Lukasiewicz(16, 16)\n",
    "            self.head = Viterbi(16, 2, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(30, 16)\n",
    "            self.layer2 = Viterbi(16, 16)\n",
    "            self.layer3 = Lukasiewicz(16, 16)\n",
    "            self.layer4 = Viterbi(16, 16)\n",
    "            self.head = Lukasiewicz(16, 2, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "        result_3 = self.layer3(result_2)\n",
    "        result_4 = self.layer4(result_3)\n",
    "\n",
    "        return self.head(result_4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:20.334882400Z",
     "start_time": "2023-11-14T20:39:20.313026600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class CirclesModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.name = \"circles\"\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(2, 8)\n",
    "            self.layer2 = Lukasiewicz(8, 8)\n",
    "            self.layer3 = Viterbi(8, 8)\n",
    "            self.layer4 = Lukasiewicz(8, 8)\n",
    "            self.head = Viterbi(8, 2, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(2, 8)\n",
    "            self.layer2 = Viterbi(8, 8)\n",
    "            self.layer3 = Lukasiewicz(8, 8)\n",
    "            self.layer4 = Viterbi(8, 8)\n",
    "            self.head = Lukasiewicz(8, 2, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "        result_3 = self.layer3(result_2)\n",
    "        result_4 = self.layer4(result_3)\n",
    "\n",
    "        return self.head(result_4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:20.894883100Z",
     "start_time": "2023-11-14T20:39:20.868333700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class RingsModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.name = \"rings\"\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(3, 8)\n",
    "            self.layer2 = Lukasiewicz(8, 8)\n",
    "            self.layer3 = Viterbi(8, 8)\n",
    "            self.layer4 = Lukasiewicz(8, 8)\n",
    "            self.head = Viterbi(8, 2, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(3, 8)\n",
    "            self.layer2 = Viterbi(8, 8)\n",
    "            self.layer3 = Lukasiewicz(8, 8)\n",
    "            self.layer4 = Viterbi(8, 8)\n",
    "            self.head = Lukasiewicz(8, 2, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "        result_3 = self.layer3(result_2)\n",
    "        result_4 = self.layer4(result_3)\n",
    "\n",
    "        return self.head(result_4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:21.365501300Z",
     "start_time": "2023-11-14T20:39:21.346243400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class SpheresModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.name = \"spheres\"\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(3, 8)\n",
    "            self.layer2 = Lukasiewicz(8, 8)\n",
    "            self.layer3 = Viterbi(8, 8)\n",
    "            self.layer4 = Lukasiewicz(8, 8)\n",
    "            self.head = Viterbi(8, 2, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(3, 8)\n",
    "            self.layer2 = Viterbi(8, 8)\n",
    "            self.layer3 = Lukasiewicz(8, 8)\n",
    "            self.layer4 = Viterbi(8, 8)\n",
    "            self.head = Lukasiewicz(8, 2, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "        result_3 = self.layer3(result_2)\n",
    "        result_4 = self.layer4(result_3)\n",
    "\n",
    "        return self.head(result_4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:22.057645800Z",
     "start_time": "2023-11-14T20:39:22.029597600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def count_parameters(parameters) -> int:\n",
    "    return sum(p.numel() for p in parameters if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:22.691228200Z",
     "start_time": "2023-11-14T20:39:22.669344700Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-14T20:39:25.086559Z",
     "start_time": "2023-11-14T20:39:25.076361Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(model: nn.Module, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    with torch.no_grad():\n",
    "        yout = model(x)\n",
    "        _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "        return (y.cpu() == prediction).sum().item() / float(y.numel())\n",
    "\n",
    "\n",
    "def test(model: nn.Module, testloader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x = x.to(device)\n",
    "            accs.append(accuracy(model, x, y))\n",
    "\n",
    "    return sum(accs) / len(accs)\n",
    "\n",
    "\n",
    "def confusion_matrix(model: nn.Module, testloader: DataLoader) -> None:\n",
    "    model.eval()\n",
    "\n",
    "    output_classes = get_features_classes_of(model.name)\n",
    "\n",
    "    conf_matrix = torch.zeros(len(output_classes), len(output_classes))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "            for i in range(len(y)):\n",
    "                conf_matrix[y[i], prediction[i]] += 1\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=output_classes, columns=output_classes).astype(int)\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=15)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=15)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def get_features_classes_of(name: str) -> list[str]:\n",
    "    if name == \"iris\":\n",
    "        output_classes = [f\"{i}\" for i in range(3)]\n",
    "    elif name == \"heart\":\n",
    "        output_classes = [f\"{i}\" for i in range(2)]\n",
    "    elif name == \"circles\":\n",
    "        output_classes = [f\"{i}\" for i in range(2)]\n",
    "    elif name == \"rings\":\n",
    "        output_classes = [f\"{i}\" for i in range(2)]\n",
    "    elif name == \"spheres\":\n",
    "        output_classes = [f\"{i}\" for i in range(2)]\n",
    "    else:\n",
    "        raise Exception(f\"Unknown model name {name}\")\n",
    "\n",
    "    return output_classes\n",
    "\n",
    "\n",
    "def train(\n",
    "        model: nn.Module,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        schedulers: list[torch.optim.lr_scheduler],\n",
    "        loss: torch.nn.modules.loss,\n",
    "        epochs: int,\n",
    "        statistics_mode: bool = False  # If True: (return max acc and do not generate output)\n",
    ") -> None | float:\n",
    "    accs = []  # list of accuracy on the test dataset for every epoch\n",
    "    trainaccs = []  # a list of the accuracies of all the training batches\n",
    "\n",
    "    if not statistics_mode:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[6, 4])\n",
    "        hdisplay = display.display(\"\", display_id=True)\n",
    "\n",
    "    for _ in trange(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.zero_grad()\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "            trainaccs.append((y.cpu() == prediction).sum().item() / float(y.numel()))\n",
    "\n",
    "            l = loss(yout, y.squeeze())\n",
    "            l.backward()\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.step()\n",
    "\n",
    "            for scheduler in schedulers:\n",
    "                scheduler.step()\n",
    "\n",
    "        accs.append(test(model, testloader))\n",
    "\n",
    "        if not statistics_mode:\n",
    "            ax.clear()\n",
    "            ax.set_xlim(0, epochs)\n",
    "            ax.set_ylim(-0.02, 1.02)\n",
    "            ax.plot(\n",
    "                np.linspace(0, len(accs), len(trainaccs)),\n",
    "                trainaccs,\n",
    "                \".\",\n",
    "                markersize=1.5,\n",
    "                markerfacecolor=(0, 0, 1, 0.3),\n",
    "            )\n",
    "            ax.plot(np.linspace(1, len(accs), len(accs)), accs)\n",
    "            ax.text(\n",
    "                0.6 * epochs,\n",
    "                0.30,\n",
    "                f\"max test acc = {max(accs):.2%}\",\n",
    "                ha=\"center\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "            hdisplay.update(fig)\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    if not statistics_mode:\n",
    "        confusion_matrix(model, testloader)\n",
    "\n",
    "    if statistics_mode:\n",
    "        return max(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def run_model_for_config(config: dict, best_accuracy: float) -> dict:\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    epochs = 20\n",
    "\n",
    "    # Create model and set data loaders\n",
    "    dataset = config[\"dataset\"]\n",
    "    if dataset == \"iris\":\n",
    "        model = IrisModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = iris_train_loader\n",
    "        testloader = iris_test_loader\n",
    "    elif dataset == \"heart\":\n",
    "        model = HeartModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = heart_train_loader\n",
    "        testloader = heart_test_loader\n",
    "    elif dataset == \"circles\":\n",
    "        model = CirclesModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = circles_train_loader\n",
    "        testloader = circles_test_loader\n",
    "    elif dataset == \"rings\":\n",
    "        model = RingsModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = rings_train_loader\n",
    "        testloader = rings_test_loader\n",
    "    elif dataset == \"spheres\":\n",
    "        model = SpheresModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = spheres_train_loader\n",
    "        testloader = spheres_test_loader\n",
    "    else:\n",
    "        raise Exception(f\"Unknown dataset: {dataset}\")\n",
    "\n",
    "    # Separate model parameters\n",
    "    viterbi_params = viterbi_parameters(model)\n",
    "    lukasiewicz_params = lukasiewicz_parameters(model)\n",
    "\n",
    "    # Create viterbi optimizer\n",
    "    viterbi_lr = config[\"viterbi_lr\"]\n",
    "    if config[\"viterbi_optimiser\"] == \"AdamW\":\n",
    "        viterbi_optimiser = ClampAdamW(viterbi_params, lr=viterbi_lr)\n",
    "    elif config[\"viterbi_optimiser\"] == \"SGD\":\n",
    "        viterbi_optimiser = ClampSGD(viterbi_params, lr=viterbi_lr)\n",
    "    else:\n",
    "        raise Exception(f\"Unknown optimiser: {config['viterbi_optimiser']}\")\n",
    "    if config[\"viterbi_scheduler\"]:\n",
    "        viterbi_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            viterbi_optimiser,\n",
    "            max_lr=viterbi_lr,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=len(trainloader),\n",
    "            epochs=epochs,\n",
    "        )\n",
    "    else:\n",
    "        viterbi_scheduler = None\n",
    "\n",
    "    # Create lukasiewicz optimizer\n",
    "    lukasiewicz_lr = config[\"viterbi_lr\"]\n",
    "    if config[\"lukasiewicz_optimiser\"] == \"AdamW\":\n",
    "        lukasiewicz_optimiser = ClampAdamW(lukasiewicz_params, lr=lukasiewicz_lr)\n",
    "    elif config[\"lukasiewicz_optimiser\"] == \"SGD\":\n",
    "        lukasiewicz_optimiser = ClampSGD(lukasiewicz_params, lr=lukasiewicz_lr)\n",
    "    else:\n",
    "        raise Exception(f\"Unknown optimiser: {config['lukasiewicz_optimiser']}\")\n",
    "    if config[\"lukasiewicz_scheduler\"]:\n",
    "        lukasiewicz_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            lukasiewicz_optimiser,\n",
    "            max_lr=lukasiewicz_lr,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=len(trainloader),\n",
    "            epochs=epochs,\n",
    "        )\n",
    "    else:\n",
    "        lukasiewicz_scheduler = None\n",
    "\n",
    "    # Create optimizers and schedulers\n",
    "    optimizers = list(filter(lambda opt: opt is not None, [viterbi_optimiser, lukasiewicz_optimiser]))\n",
    "    schedulers = list(filter(lambda sch: sch is not None, [viterbi_scheduler, lukasiewicz_scheduler]))\n",
    "\n",
    "    reported_accuracy, last_reported_accuracy = [], []\n",
    "    for epoch in range(epochs):\n",
    "        last_reported_accuracy = reported_accuracy\n",
    "\n",
    "        # Feed to training function\n",
    "        reported_accuracy = train_model(\n",
    "            model,\n",
    "            trainloader,\n",
    "            testloader,\n",
    "            optimizers,\n",
    "            schedulers,\n",
    "            loss,\n",
    "        )\n",
    "\n",
    "        # Try some stopping conditions\n",
    "        if (((epoch > 2) and (reported_accuracy < 0.15))\n",
    "                or ((epoch > 5) and (reported_accuracy < best_accuracy / 2))\n",
    "                or ((epoch > 2) and (abs(last_reported_accuracy - reported_accuracy) < 1e-6))):\n",
    "            # Run is done, no sense to train it any further\n",
    "            # or bad trial\n",
    "            break  # Break for-loop to report\n",
    "\n",
    "    return {\"accuracy\": reported_accuracy, \"config\": config}\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        schedulers: list[torch.optim.lr_scheduler],\n",
    "        loss: torch.nn.modules.loss,\n",
    ") -> float:\n",
    "    model.train()\n",
    "\n",
    "    for x, y in trainloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        l = loss(model(x), y.squeeze())\n",
    "        l.backward()\n",
    "\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        for scheduler in schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return test(model, testloader)\n",
    "\n",
    "\n",
    "def run_random_search_for_config(config: dict) -> dict:\n",
    "    best_accuracy, best_config, current_config = 0, deepcopy(config), deepcopy(config)\n",
    "    step_size, bad_step_counter, good_step_counter = 0.1, 0, 0\n",
    "    for num_trial in range(100):\n",
    "        result = run_model_for_config(current_config, best_accuracy=best_accuracy)\n",
    "\n",
    "        if result[\"accuracy\"] > best_accuracy:\n",
    "            bad_step_counter = 0\n",
    "            good_step_counter += 1\n",
    "\n",
    "            best_accuracy, best_config = result[\"accuracy\"], deepcopy(current_config)\n",
    "        else:\n",
    "            bad_step_counter += 1\n",
    "            good_step_counter = 0\n",
    "\n",
    "        if bad_step_counter > 10:\n",
    "            break  # Terminate run, likely no better accuracy possible\n",
    "\n",
    "        current_config, step_size, bad_step_counter, good_step_counter = adaptive_step_update_config(\n",
    "            config=deepcopy(best_config),\n",
    "            step_size=step_size,\n",
    "            bad_step_counter=bad_step_counter,\n",
    "            good_step_counter=good_step_counter,\n",
    "        )\n",
    "\n",
    "        if step_size < 1e-2:\n",
    "            # Step size too small to make any impact, terminate run\n",
    "            break\n",
    "\n",
    "    return {\"accuracy\": best_accuracy, \"config\": best_config}\n",
    "\n",
    "\n",
    "def adaptive_step_update_config(\n",
    "        config: dict,\n",
    "        step_size: float,\n",
    "        bad_step_counter: int,\n",
    "        good_step_counter: int,\n",
    ") -> tuple[dict, float, int, int]:\n",
    "    # Update step_size\n",
    "    if bad_step_counter > 2:\n",
    "        step_size /= 2\n",
    "        bad_step_counter = 0\n",
    "    if (good_step_counter > 2) and (step_size < 0.5):\n",
    "        step_size *= 2\n",
    "        good_step_counter = 0\n",
    "\n",
    "    # Update config values\n",
    "    config[\"viterbi_lr\"] = uniform(\n",
    "        config[\"viterbi_lr\"] * (1 - step_size),\n",
    "        config[\"viterbi_lr\"] * (1 + step_size),\n",
    "    )\n",
    "    config[\"lukasiewicz_lr\"] = uniform(\n",
    "        config[\"lukasiewicz_lr\"] * (1 - step_size),\n",
    "        config[\"lukasiewicz_lr\"] * (1 + step_size),\n",
    "    )\n",
    "\n",
    "    return config, step_size, bad_step_counter, good_step_counter\n",
    "\n",
    "\n",
    "def find_best_model_for(config: dict) -> None:\n",
    "    # current_config, results = deepcopy(config), []\n",
    "\n",
    "    # for viterbi_optimiser in [\"AdamW\", \"SGD\"]:\n",
    "    #     current_config[\"viterbi_optimiser\"] = viterbi_optimiser\n",
    "    #     for viterbi_scheduler in [True, False]:\n",
    "    #         current_config[\"viterbi_scheduler\"] = viterbi_scheduler\n",
    "    #         for lukasiewicz_optimiser in [\"AdamW\", \"SGD\"]:\n",
    "    #             current_config[\"lukasiewicz_optimiser\"] = lukasiewicz_optimiser\n",
    "    #             for lukasiewicz_scheduler in [True, False]:\n",
    "    #                 current_config[\"lukasiewicz_scheduler\"] = lukasiewicz_scheduler\n",
    "    # \n",
    "    #                 result, counter = {\"accuracy\": 0, \"config\": {}}, 0\n",
    "    #                 while counter < 5:\n",
    "    #                     current_config = create_random_config_for_model(deepcopy(current_config))\n",
    "    #                     print(f\"Starting semiring run for config {current_config}\")\n",
    "    #                     subresult = run_random_search_for_config(current_config)\n",
    "    #                     if subresult[\"accuracy\"] > result[\"accuracy\"]:\n",
    "    #                         result = subresult\n",
    "    #                     counter += 1\n",
    "    # \n",
    "    #                 display.clear_output(wait=True)\n",
    "    #                 results.append(result)\n",
    "    \n",
    "\n",
    "    # sorted_results = sorted(results, key=lambda dictionary: dictionary[\"accuracy\"], reverse=True)\n",
    "\n",
    "    # display.clear_output(wait=True)\n",
    "    # print(f'Best trial config with accuracy of {sorted_results[0][\"accuracy\"]}: {sorted_results[0][\"config\"]}')\n",
    "    # print(f\"-----------------\")\n",
    "    # print(*sorted_results, sep=\"\\n\")\n",
    "    \n",
    "    result = {\"accuracy\": 0, \"config\": {}}\n",
    "    while result[\"accuracy\"] < 0.5:\n",
    "        current_config = create_random_config_for_model(deepcopy(config))\n",
    "\n",
    "        print(f\"Starting run for config {current_config}\")\n",
    "        result = run_random_search_for_config(current_config)\n",
    "        result2 = run_model_for_config(current_config, result[\"accuracy\"])\n",
    "        if abs(result[\"accuracy\"] - result2[\"accuracy\"]) > 0.2:\n",
    "            result[\"accuracy\"] = 0\n",
    "        print(f\"Accuracy = {result['accuracy']}\")\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "def create_random_config_for_model(config: dict) -> dict:\n",
    "    config[\"viterbi_lr\"] = 10 ** uniform(-3, -1)\n",
    "    config[\"lukasiewicz_lr\"] = 10 ** uniform(-3, -1)\n",
    "\n",
    "    return config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T19:41:51.508901900Z",
     "start_time": "2023-11-17T19:41:51.499957500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iris"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config with accuracy of 0.5666666666666667: {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.013297377295240047, 'lukasiewicz_lr': 0.01086887540342563}\n",
      "-----------------\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.013297377295240047, 'lukasiewicz_lr': 0.01086887540342563}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.017145480470434057, 'lukasiewicz_lr': 0.004983323107451874}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.018768884400649232, 'lukasiewicz_lr': 0.014152878055713929}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.033819884329598204, 'lukasiewicz_lr': 0.0031878048256277084}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.016908216444986295, 'lukasiewicz_lr': 0.004200739209777875}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.009970981326610727, 'lukasiewicz_lr': 0.0017231455097293821}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.07231706421527999, 'lukasiewicz_lr': 0.001755066127397716}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.056929118949215506, 'lukasiewicz_lr': 0.004521954647258974}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.07813293492712299, 'lukasiewicz_lr': 0.013827323338326087}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.026785018402603004, 'lukasiewicz_lr': 0.01232462806997476}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.07617608346956296, 'lukasiewicz_lr': 0.02354993772829173}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.08419714654503355, 'lukasiewicz_lr': 0.03134595348753708}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.04231263317467274, 'lukasiewicz_lr': 0.002134368360898554}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.08073729343483876, 'lukasiewicz_lr': 0.0715367887663977}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.06890913107572585, 'lukasiewicz_lr': 0.007644954282092014}}\n",
      "{'accuracy': 0.23333333333333334, 'config': {'dataset': 'iris', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.006711901691596562, 'lukasiewicz_lr': 0.002486222916831955}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"iris\",\n",
    "    \"reverse\": False,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config with accuracy of 0.5666666666666667: {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0060436198329632965, 'lukasiewicz_lr': 0.0850385320576317}\n",
      "-----------------\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0060436198329632965, 'lukasiewicz_lr': 0.0850385320576317}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.07100179268991495, 'lukasiewicz_lr': 0.0033353434517794708}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.010590066432397592, 'lukasiewicz_lr': 0.005098655808909461}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.04054131199033576, 'lukasiewicz_lr': 0.009653591503801061}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.01316709409234872, 'lukasiewicz_lr': 0.02019095857652618}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.006665436335842091, 'lukasiewicz_lr': 0.009143360417009956}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0692446302106546, 'lukasiewicz_lr': 0.006060974750215989}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.027469016569257015, 'lukasiewicz_lr': 0.022801765216444857}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.03721920160249401, 'lukasiewicz_lr': 0.006839840023089145}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.013604852713174936, 'lukasiewicz_lr': 0.03082758788601648}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0408962165678511, 'lukasiewicz_lr': 0.05724255601293901}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.021569133495307865, 'lukasiewicz_lr': 0.005217165375875481}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0371261464099134, 'lukasiewicz_lr': 0.022693888306100096}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.01677719810328527, 'lukasiewicz_lr': 0.006442048726274448}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.08212842966041001, 'lukasiewicz_lr': 0.0010948927501396772}}\n",
      "{'accuracy': 0.5666666666666667, 'config': {'dataset': 'iris', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.09078287200482094, 'lukasiewicz_lr': 0.005885094710708048}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"iris\",\n",
    "    \"reverse\": True,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = IrisModel(reverse=False).to(device)\n",
    "print(f\"Model has {count_parameters(model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(viterbi_parameters(model))} are Viterbi \"\n",
    "      f\"and {count_parameters(lukasiewicz_parameters(model))} are Lukasiewicz related\")\n",
    "\n",
    "viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.0053267031097706755)\n",
    "lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.006008866355250269)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    iris_train_loader,\n",
    "    iris_test_loader,\n",
    "    [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "    [],\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    model = IrisModel(reverse=False).to(device)\n",
    "    \n",
    "    viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.0053267031097706755)\n",
    "    lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.006008866355250269)\n",
    "    \n",
    "    accs.append(train(\n",
    "        model,\n",
    "        iris_train_loader,\n",
    "        iris_test_loader,\n",
    "        [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "        [],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "print(min(accs))\n",
    "print(quantiles(accs))\n",
    "print(max(accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Heart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config with accuracy of 0.5245901639344263: {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0010749994691098342, 'lukasiewicz_lr': 0.0035892709623141614}\n",
      "-----------------\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0010749994691098342, 'lukasiewicz_lr': 0.0035892709623141614}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0012649322563327331, 'lukasiewicz_lr': 0.08644985432517231}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.06552053235846322, 'lukasiewicz_lr': 0.05235525244998469}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.006999345701367499, 'lukasiewicz_lr': 0.00725497341233944}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0022866469641668772, 'lukasiewicz_lr': 0.0014571737758590868}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.03106803054279518, 'lukasiewicz_lr': 0.08984594552823658}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.05420782841700873, 'lukasiewicz_lr': 0.021239725276725917}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0017229721401931179, 'lukasiewicz_lr': 0.08864591260772323}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.06044016409312681, 'lukasiewicz_lr': 0.015922438736653725}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.00838560750381185, 'lukasiewicz_lr': 0.03841067535638973}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0010446412840386964, 'lukasiewicz_lr': 0.028540228181049197}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.061841649714666554, 'lukasiewicz_lr': 0.03207139559175166}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0994290968540191, 'lukasiewicz_lr': 0.05943762330895995}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.062320069376146175, 'lukasiewicz_lr': 0.005294549540172859}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.010528437975665056, 'lukasiewicz_lr': 0.042382704585396835}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.08649151466108489, 'lukasiewicz_lr': 0.0047136450559810165}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"heart\",\n",
    "    \"reverse\": False,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config with accuracy of 0.5245901639344263: {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.09621460299711752, 'lukasiewicz_lr': 0.015668823862304816}\n",
      "-----------------\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.09621460299711752, 'lukasiewicz_lr': 0.015668823862304816}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.006376466820570098, 'lukasiewicz_lr': 0.019231186412614506}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.07141641209303604, 'lukasiewicz_lr': 0.01130358463306801}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.07822531219280082, 'lukasiewicz_lr': 0.07657255990024153}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.013754312237006442, 'lukasiewicz_lr': 0.01870314913267129}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.09170443419974666, 'lukasiewicz_lr': 0.0022586823725947633}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.010793626428721035, 'lukasiewicz_lr': 0.008466523954434766}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0236775811053956, 'lukasiewicz_lr': 0.03809157949411382}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.007225448279111766, 'lukasiewicz_lr': 0.010394842297762722}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0708253759783599, 'lukasiewicz_lr': 0.05292632798430895}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0015309229721804916, 'lukasiewicz_lr': 0.001718782677617612}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.02054995074992018, 'lukasiewicz_lr': 0.0034171495488738786}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.04067772320657437, 'lukasiewicz_lr': 0.02318561596375106}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0019810839152054212, 'lukasiewicz_lr': 0.009813174660787396}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.08631481975764595, 'lukasiewicz_lr': 0.0030356901991997493}}\n",
      "{'accuracy': 0.5245901639344263, 'config': {'dataset': 'heart', 'reverse': True, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0014127658457526724, 'lukasiewicz_lr': 0.006373616184956758}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"heart\",\n",
    "    \"reverse\": True,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = HeartModel(reverse=False).to(device)\n",
    "print(f\"Model has {count_parameters(model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(viterbi_parameters(model))} are Viterbi \"\n",
    "      f\"and {count_parameters(lukasiewicz_parameters(model))} are Lukasiewicz related\")\n",
    "\n",
    "viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.0010436799070880863)\n",
    "lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.007398253759093079)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    heart_train_loader,\n",
    "    heart_test_loader,\n",
    "    [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "    [],\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    model = HeartModel(reverse=False).to(device)\n",
    "    \n",
    "    viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.0053267031097706755)\n",
    "    lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.006008866355250269)\n",
    "    \n",
    "    accs.append(train(\n",
    "        model,\n",
    "        heart_train_loader,\n",
    "        heart_test_loader,\n",
    "        [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "        [],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "print(min(accs))\n",
    "print(quantiles(accs))\n",
    "print(max(accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Circles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config with accuracy of 0.6285266457680251: {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.006838579252617862, 'lukasiewicz_lr': 0.005487104130213599}\n",
      "-----------------\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.006838579252617862, 'lukasiewicz_lr': 0.005487104130213599}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.002624766116490802, 'lukasiewicz_lr': 0.09836043973642494}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0012382035377972716, 'lukasiewicz_lr': 0.08752131399295944}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0015447235401587758, 'lukasiewicz_lr': 0.017041577826280796}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.01186342848295125, 'lukasiewicz_lr': 0.08517510953967902}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.002705404404523951, 'lukasiewicz_lr': 0.020324743705125672}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.05773242199961686, 'lukasiewicz_lr': 0.0019437364037688356}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'AdamW', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0024465338531233153, 'lukasiewicz_lr': 0.034106843779653714}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0011433980913026014, 'lukasiewicz_lr': 0.09964091054525127}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0014433617716086127, 'lukasiewicz_lr': 0.05057455465802466}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0028953618037629047, 'lukasiewicz_lr': 0.015834516769222838}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': True, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.01981850304428696, 'lukasiewicz_lr': 0.0011654429076649931}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0747803164152842, 'lukasiewicz_lr': 0.0623524898975513}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'AdamW', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.003399796023676148, 'lukasiewicz_lr': 0.006093480293599216}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': True, 'viterbi_lr': 0.0035170157857170752, 'lukasiewicz_lr': 0.0012751951661827666}}\n",
      "{'accuracy': 0.6285266457680251, 'config': {'dataset': 'circles', 'reverse': False, 'viterbi_optimiser': 'SGD', 'viterbi_scheduler': False, 'lukasiewicz_optimiser': 'SGD', 'lukasiewicz_scheduler': False, 'viterbi_lr': 0.0012064406686750895, 'lukasiewicz_lr': 0.0380857349285926}}\n"
     ]
    }
   ],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"circles\",\n",
    "    \"reverse\": False,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"circles\",\n",
    "    \"reverse\": True,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CirclesModel(reverse=False).to(device)\n",
    "print(f\"Model has {count_parameters(model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(viterbi_parameters(model))} are Viterbi \"\n",
    "      f\"and {count_parameters(lukasiewicz_parameters(model))} are Lukasiewicz related\")\n",
    "\n",
    "viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.05971752653541055)\n",
    "lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.05971752653541055)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    circles_train_loader,\n",
    "    circles_test_loader,\n",
    "    [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "    [],\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    model = CirclesModel(reverse=False).to(device)\n",
    "    \n",
    "    viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.0053267031097706755)\n",
    "    lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.006008866355250269)\n",
    "    \n",
    "    accs.append(train(\n",
    "        model,\n",
    "        circles_train_loader,\n",
    "        circles_test_loader,\n",
    "        [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "        [],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "print(min(accs))\n",
    "print(quantiles(accs))\n",
    "print(max(accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"rings\",\n",
    "    \"reverse\": False,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T19:41:27.119980500Z",
     "start_time": "2023-11-17T19:41:27.119980500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"rings\",\n",
    "    \"reverse\": True,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T19:41:27.134417900Z",
     "start_time": "2023-11-17T19:41:27.119980500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RingsModel(reverse=False).to(device)\n",
    "print(f\"Model has {count_parameters(model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(viterbi_parameters(model))} are Viterbi \"\n",
    "      f\"and {count_parameters(lukasiewicz_parameters(model))} are Lukasiewicz related\")\n",
    "\n",
    "viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.05971752653541055)\n",
    "lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.05971752653541055)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    rings_train_loader,\n",
    "    rings_test_loader,\n",
    "    [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "    [],\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    model = RingsModel(reverse=False).to(device)\n",
    "    \n",
    "    viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.0053267031097706755)\n",
    "    lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.006008866355250269)\n",
    "    \n",
    "    accs.append(train(\n",
    "        model,\n",
    "        rings_train_loader,\n",
    "        rings_test_loader,\n",
    "        [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "        [],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "print(min(accs))\n",
    "print(quantiles(accs))\n",
    "print(max(accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spheres"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"spheres\",\n",
    "    \"reverse\": False,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T19:41:27.121963400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"spheres\",\n",
    "    \"reverse\": True,\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T19:41:27.122955900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SpheresModel(reverse=False).to(device)\n",
    "print(f\"Model has {count_parameters(model.parameters())} trainable parameters, \"\n",
    "      f\"of which {count_parameters(viterbi_parameters(model))} are Viterbi \"\n",
    "      f\"and {count_parameters(lukasiewicz_parameters(model))} are Lukasiewicz related\")\n",
    "\n",
    "viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.05971752653541055)\n",
    "lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.05971752653541055)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    spheres_train_loader,\n",
    "    spheres_test_loader,\n",
    "    [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "    [],\n",
    "    nn.CrossEntropyLoss(),\n",
    "    20,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accs = []\n",
    "\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    \n",
    "    model = SpheresModel(reverse=False).to(device)\n",
    "    \n",
    "    viterbi_optimiser = ClampSGD(viterbi_parameters(model), lr=0.0053267031097706755)\n",
    "    lukasiewicz_optimiser = ClampSGD(lukasiewicz_parameters(model), lr=0.006008866355250269)\n",
    "\n",
    "    accs.append(train(\n",
    "        model,\n",
    "        spheres_train_loader,\n",
    "        spheres_test_loader,\n",
    "        [viterbi_optimiser, lukasiewicz_optimiser],\n",
    "        [],\n",
    "        nn.CrossEntropyLoss(),\n",
    "        20,\n",
    "        statistics_mode=True,\n",
    "    ))\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "print(min(accs))\n",
    "print(quantiles(accs))\n",
    "print(max(accs))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
