{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Experiments\n",
    "\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from IPython import display\n",
    "from random import uniform\n",
    "from semitorch import (\n",
    "    Viterbi, viterbi_parameters,\n",
    "    Lukasiewicz, lukasiewicz_parameters,\n",
    ")\n",
    "from statistics import quantiles\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "data_path = os.path.abspath(\"./data\" if os.path.isdir(\"./data\") else \"../../data\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def split_dataset(dataset: torch.utils.data.Dataset):\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "\n",
    "    return torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load iris data\n",
    "[https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\n",
    "    os.path.join(data_path, \"iris.csv\"), index_col=0, dtype={\"Species\": \"string\"}\n",
    ")\n",
    "iris_x = torch.Tensor(iris_df.iloc[:, [0, 1, 2, 3]].to_numpy()).to(device)\n",
    "\n",
    "iris_y = (\n",
    "    iris_df[\"Species\"]\n",
    "    .map({\n",
    "        \"Iris-setosa\": 0,\n",
    "        \"Iris-versicolor\": 1,\n",
    "        \"Iris-virginica\": 2,\n",
    "    }).to_numpy()\n",
    ")\n",
    "iris_y = torch.Tensor(iris_y).to(torch.int64).to(device)\n",
    "print(f\"Iris dataset: input features = {iris_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(iris_y).shape[0]}, \"\n",
    "      f\"samples = {len(iris_y)}\")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(iris_x, dim=0, out=iris_x)\n",
    "\n",
    "iris_train, iris_test = split_dataset(torch.utils.data.TensorDataset(iris_x, iris_y))\n",
    "\n",
    "iris_train_loader = DataLoader(iris_train, batch_size=8, shuffle=True)\n",
    "iris_test_loader = DataLoader(iris_test, batch_size=len(iris_test), shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load heart disease data\n",
    "\n",
    "[https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df = pd.read_csv(os.path.join(data_path, \"heart.csv\"))\n",
    "heart_x = (torch.Tensor(heart_df.iloc[:, range(13)].to_numpy()).to(torch.float32).to(device))\n",
    "heart_y = torch.Tensor(heart_df.iloc[:, -1].to_numpy()).to(torch.int64).to(device)\n",
    "\n",
    "print(f\"Heart disease dataset: input features = {heart_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(heart_y).shape[0]}, \"\n",
    "      f\"samples = {len(heart_y)}\")\n",
    "\n",
    "# normalize\n",
    "torch.nn.functional.normalize(heart_x, dim=0, out=heart_x)\n",
    "\n",
    "heart_train, heart_test = split_dataset(torch.utils.data.TensorDataset(heart_x, heart_y))\n",
    "\n",
    "heart_train_loader = DataLoader(heart_train, batch_size=32, shuffle=True)\n",
    "heart_test_loader = DataLoader(heart_test, batch_size=len(heart_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Naitzat data\n",
    "\n",
    "[https://github.com/topnn/topnn_framework](https://github.com/topnn/topnn_framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles_x, circles_y = torch.load(os.path.join(data_path, \"naitzat\", \"circles_type_8.pt\"))\n",
    "circles_y = torch.squeeze(circles_y)\n",
    "circles_train, circles_test = split_dataset(torch.utils.data.TensorDataset(circles_x, circles_y))\n",
    "print(f\"Circles dataset: input features = {circles_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(circles_y).shape[0]}, \"\n",
    "      f\"samples = {len(circles_y)}\")\n",
    "circles_train_loader = DataLoader(circles_train, batch_size=16, shuffle=True)\n",
    "circles_test_loader = DataLoader(circles_test, batch_size=len(circles_test), shuffle=True)\n",
    "\n",
    "rings_x, rings_y = torch.load(os.path.join(data_path, \"naitzat\", \"rings_9.pt\"))\n",
    "rings_y = torch.squeeze(rings_y)\n",
    "rings_train, rings_test = split_dataset(torch.utils.data.TensorDataset(rings_x, rings_y))\n",
    "print(f\"Rings dataset: input features = {rings_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(rings_y).shape[0]}, \"\n",
    "      f\"samples = {len(rings_y)}\")\n",
    "rings_train_loader = DataLoader(rings_train, batch_size=16, shuffle=True)\n",
    "rings_test_loader = DataLoader(rings_test, batch_size=len(rings_test), shuffle=True)\n",
    "\n",
    "spheres_x, spheres_y = torch.load(os.path.join(data_path, \"naitzat\", \"spheres_9.pt\"))\n",
    "spheres_y = torch.squeeze(spheres_y)\n",
    "spheres_train, spheres_test = split_dataset(torch.utils.data.TensorDataset(spheres_x, spheres_y))\n",
    "print(f\"Spheres dataset: input features = {spheres_x.shape[1]}, \"\n",
    "      f\"classes = {torch.unique(spheres_y).shape[0]}, \"\n",
    "      f\"samples = {len(spheres_y)}\")\n",
    "spheres_train_loader = DataLoader(spheres_train, batch_size=16, shuffle=True)\n",
    "spheres_test_loader = DataLoader(spheres_test, batch_size=len(spheres_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FashionMNIST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_workers = 8\n",
    "\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.286,), (0.353,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fmnist_trainset = FashionMNIST(root=\"../.\", train=True, download=True, transform=transforms_train)\n",
    "fmnist_testset = FashionMNIST(root=\"../.\", train=False, download=True, transform=transforms_test)\n",
    "\n",
    "fmnist_trainloader = DataLoader(fmnist_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "fmnist_testloader = DataLoader(fmnist_testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "class IrisModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(4, 16)\n",
    "            self.layer2 = Lukasiewicz(16, 16)\n",
    "            self.head = Viterbi(16, 3, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(4, 16)\n",
    "            self.layer2 = Viterbi(16, 16)\n",
    "            self.head = Lukasiewicz(16, 3, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "\n",
    "        return self.head(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class HeartModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(13, 16)\n",
    "            self.layer2 = Lukasiewicz(16, 16)\n",
    "            self.layer3 = Viterbi(16, 16)\n",
    "            self.layer4 = Lukasiewicz(16, 16)\n",
    "            self.head = Viterbi(16, 2, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(13, 16)\n",
    "            self.layer2 = Viterbi(16, 16)\n",
    "            self.layer3 = Lukasiewicz(16, 16)\n",
    "            self.layer4 = Viterbi(16, 16)\n",
    "            self.head = Lukasiewicz(16, 2, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "        result_3 = self.layer3(result_2)\n",
    "        result_4 = self.layer4(result_3)\n",
    "\n",
    "        return self.head(result_4)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CirclesModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(2, 8)\n",
    "            self.layer2 = Lukasiewicz(8, 8)\n",
    "            self.layer3 = Viterbi(8, 8)\n",
    "            self.layer4 = Lukasiewicz(8, 8)\n",
    "            self.head = Viterbi(8, 2, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(2, 8)\n",
    "            self.layer2 = Viterbi(8, 8)\n",
    "            self.layer3 = Lukasiewicz(8, 8)\n",
    "            self.layer4 = Viterbi(8, 8)\n",
    "            self.head = Lukasiewicz(8, 2, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "        result_3 = self.layer3(result_2)\n",
    "        result_4 = self.layer4(result_3)\n",
    "\n",
    "        return self.head(result_4)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RingsAndSpheresModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer1 = Viterbi(3, 8)\n",
    "            self.layer2 = Lukasiewicz(8, 8)\n",
    "            self.layer3 = Viterbi(8, 8)\n",
    "            self.layer4 = Lukasiewicz(8, 8)\n",
    "            self.head = Viterbi(8, 2, bias=False)\n",
    "        else:\n",
    "            self.layer1 = Lukasiewicz(3, 8)\n",
    "            self.layer2 = Viterbi(8, 8)\n",
    "            self.layer3 = Lukasiewicz(8, 8)\n",
    "            self.layer4 = Viterbi(8, 8)\n",
    "            self.head = Lukasiewicz(8, 2, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_1 = self.layer1(x)\n",
    "        result_2 = self.layer2(result_1)\n",
    "        result_3 = self.layer3(result_2)\n",
    "        result_4 = self.layer4(result_3)\n",
    "\n",
    "        return self.head(result_4)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class FashionModel(nn.Module):\n",
    "    def __init__(self, reverse: bool = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = nn.Flatten()\n",
    "\n",
    "        if not reverse:\n",
    "            self.layer_1 = Viterbi(784, 600)\n",
    "            self.layer_2 = Lukasiewicz(600, 500)\n",
    "            self.layer_3 = Viterbi(500 + 600, 400)\n",
    "            self.layer_4 = Lukasiewicz(400 + 500, 300)\n",
    "            self.layer_5 = Viterbi(300 + 400, 200)\n",
    "            self.layer_6 = Lukasiewicz(200 + 300, 100)\n",
    "            self.head = Viterbi(100 + 200, 10, bias=False)\n",
    "        else:\n",
    "            self.layer_1 = Lukasiewicz(784, 600)\n",
    "            self.layer_2 = Viterbi(600, 500)\n",
    "            self.layer_3 = Lukasiewicz(500 + 600, 400)\n",
    "            self.layer_4 = Viterbi(400 + 500, 300)\n",
    "            self.layer_5 = Lukasiewicz(300 + 400, 200)\n",
    "            self.layer_6 = Viterbi(200 + 300, 100)\n",
    "            self.head = Lukasiewicz(100 + 200, 10, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        result_0 = self.stem(x)\n",
    "\n",
    "        result_1 = self.layer_1(result_0)\n",
    "        result_2 = self.layer_2(result_1)\n",
    "        result_3 = self.layer_3(torch.cat((result_2, result_1), dim=-1))\n",
    "        result_4 = self.layer_4(torch.cat((result_3, result_2), dim=-1))\n",
    "        result_5 = self.layer_5(torch.cat((result_4, result_3), dim=-1))\n",
    "        result_6 = self.layer_6(torch.cat((result_5, result_4), dim=-1))\n",
    "\n",
    "        return self.head(torch.cat((result_6, result_5), dim=-1))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_parameters(parameters) -> int:\n",
    "    return sum(p.numel() for p in parameters if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def accuracy(model: nn.Module, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "    with torch.no_grad():\n",
    "        yout = model(x)\n",
    "        _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "        return (y.cpu() == prediction).sum().item() / float(y.numel())\n",
    "\n",
    "\n",
    "def test(model: nn.Module, testloader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x = x.to(device)\n",
    "            accs.append(accuracy(model, x, y))\n",
    "\n",
    "    return sum(accs) / len(accs)\n",
    "\n",
    "\n",
    "def confusion_matrix(model: nn.Module, testloader: DataLoader) -> None:\n",
    "    model.eval()\n",
    "\n",
    "    conf_matrix = torch.zeros(len(fmnist_testset.classes), len(fmnist_testset.classes))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "\n",
    "            conf_matrix[y.cpu(), prediction] += 1\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=fmnist_testset.classes, columns=fmnist_testset.classes).astype(int)\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=15)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=15)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "def train(\n",
    "        model: nn.Module,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        schedulers: list[torch.optim.lr_scheduler],\n",
    "        loss: torch.nn.modules.loss,\n",
    "        epochs: int,\n",
    "        statistics_mode: bool = False  # If True: (return max acc and do not generate output)\n",
    ") -> None | float:\n",
    "    accs = []  # list of accuracy on the test dataset for every epoch\n",
    "    trainaccs = []  # a list of the accuracies of all the training batches\n",
    "\n",
    "    if not statistics_mode:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[6, 4])\n",
    "        hdisplay = display.display(\"\", display_id=True)\n",
    "\n",
    "    for _ in trange(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for x, y in trainloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.zero_grad()\n",
    "            yout = model(x)\n",
    "            _, prediction = torch.max(yout.cpu(), dim=1)\n",
    "            trainaccs.append((y.cpu() == prediction).sum().item() / float(y.numel()))\n",
    "\n",
    "            l = loss(yout, y.squeeze())\n",
    "            l.backward()\n",
    "            for optimizer in optimizers:\n",
    "                optimizer.step()\n",
    "\n",
    "            for scheduler in schedulers:\n",
    "                scheduler.step()\n",
    "\n",
    "        accs.append(test(model, testloader))\n",
    "\n",
    "        if not statistics_mode:\n",
    "            ax.clear()\n",
    "            ax.set_xlim(0, epochs)\n",
    "            ax.set_ylim(-0.02, 1.02)\n",
    "            ax.plot(\n",
    "                np.linspace(0, len(accs), len(trainaccs)),\n",
    "                trainaccs,\n",
    "                \".\",\n",
    "                markersize=1.5,\n",
    "                markerfacecolor=(0, 0, 1, 0.3),\n",
    "            )\n",
    "            ax.plot(np.linspace(1, len(accs), len(accs)), accs)\n",
    "            ax.text(\n",
    "                0.6 * epochs,\n",
    "                0.30,\n",
    "                f\"max test acc = {max(accs):.2%}\",\n",
    "                ha=\"center\",\n",
    "                fontsize=10,\n",
    "            )\n",
    "            hdisplay.update(fig)\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    if not statistics_mode:\n",
    "        confusion_matrix(model, testloader)\n",
    "\n",
    "    if statistics_mode:\n",
    "        return max(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_model_for_config(config: dict, best_accuracy: float) -> dict:\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    epochs = 20\n",
    "\n",
    "    # Create model and set data loaders\n",
    "    dataset = config[\"dataset\"]\n",
    "    if dataset == \"iris\":\n",
    "        model = IrisModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = iris_train_loader\n",
    "        testloader = iris_test_loader\n",
    "    elif dataset == \"heart\":\n",
    "        model = HeartModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = heart_train_loader\n",
    "        testloader = heart_test_loader\n",
    "    elif dataset == \"circles\":\n",
    "        model = CirclesModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = circles_train_loader\n",
    "        testloader = circles_test_loader\n",
    "    elif dataset in [\"rings\", \"spheres\"]:\n",
    "        model = RingsAndSpheresModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = rings_train_loader\n",
    "        testloader = rings_test_loader\n",
    "    elif dataset == \"fashion\":\n",
    "        model = FashionModel(reverse=config[\"reverse\"]).to(device)\n",
    "        trainloader = fmnist_trainloader\n",
    "        testloader = fmnist_testloader\n",
    "    else:\n",
    "        raise Exception(f\"Unknown dataset: {dataset}\")\n",
    "\n",
    "    # Separate model parameters\n",
    "    viterbi_params = viterbi_parameters(model)\n",
    "    lukasiewicz_params = lukasiewicz_parameters(model)\n",
    "\n",
    "    # Create viterbi optimizer\n",
    "    viterbi_lr = config[\"viterbi_lr\"]\n",
    "    viterbi_optimizer = torch.optim.AdamW(viterbi_params, lr=viterbi_lr)\n",
    "    if config[\"viterbi_scheduler\"]:\n",
    "        viterbi_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            viterbi_optimizer,\n",
    "            max_lr=viterbi_lr,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=len(trainloader),\n",
    "            epochs=epochs,\n",
    "        )\n",
    "    else:\n",
    "        viterbi_scheduler = None\n",
    "\n",
    "    # Create lukasiewicz optimizer\n",
    "    lukasiewicz_lr = config[\"viterbi_lr\"]\n",
    "    lukasiewicz_optimizer = torch.optim.AdamW(lukasiewicz_params, lr=lukasiewicz_lr)\n",
    "    if config[\"lukasiewicz_scheduler\"]:\n",
    "        lukasiewicz_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            lukasiewicz_optimizer,\n",
    "            max_lr=lukasiewicz_lr,\n",
    "            anneal_strategy=\"linear\",\n",
    "            pct_start=0.3,\n",
    "            three_phase=True,\n",
    "            final_div_factor=1000.0,\n",
    "            div_factor=10.0,\n",
    "            steps_per_epoch=len(trainloader),\n",
    "            epochs=epochs,\n",
    "        )\n",
    "    else:\n",
    "        lukasiewicz_scheduler = None\n",
    "\n",
    "    # Create optimizers and schedulers\n",
    "    optimizers = list(filter(lambda opt: opt is not None, [viterbi_optimizer, lukasiewicz_optimizer]))\n",
    "    schedulers = list(filter(lambda sch: sch is not None, [viterbi_scheduler, lukasiewicz_scheduler]))\n",
    "\n",
    "    reported_accuracy, last_reported_accuracy = [], []\n",
    "    for epoch in range(epochs):\n",
    "        last_reported_accuracy = reported_accuracy\n",
    "\n",
    "        # Feed to training function\n",
    "        reported_accuracy = train_model(\n",
    "            model,\n",
    "            trainloader,\n",
    "            testloader,\n",
    "            optimizers,\n",
    "            schedulers,\n",
    "            loss,\n",
    "        )\n",
    "\n",
    "        # Try some stopping conditions\n",
    "        if (((epoch > 2) and (reported_accuracy < 0.15))\n",
    "                or ((epoch > 5) and (reported_accuracy < best_accuracy / 2))\n",
    "                or ((epoch > 2) and (abs(last_reported_accuracy - reported_accuracy) < 1e-6))):\n",
    "            # Run is done, no sense to train it any further\n",
    "            # or bad trial\n",
    "            break  # Break for-loop to report\n",
    "\n",
    "    return {\"accuracy\": reported_accuracy, \"config\": config}\n",
    "\n",
    "\n",
    "def train_model(\n",
    "        model: nn.Module,\n",
    "        trainloader: DataLoader,\n",
    "        testloader: DataLoader,\n",
    "        optimizers: list[torch.optim.Optimizer],\n",
    "        schedulers: list[torch.optim.lr_scheduler],\n",
    "        loss: torch.nn.modules.loss,\n",
    ") -> float:\n",
    "    model.train()\n",
    "\n",
    "    for x, y in trainloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        l = loss(model(x), y.squeeze())\n",
    "        l.backward()\n",
    "\n",
    "        for optimizer in optimizers:\n",
    "            optimizer.step()\n",
    "\n",
    "        for scheduler in schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        # prevents OOM when GPU memory is tight\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    return test(model, testloader)\n",
    "\n",
    "\n",
    "def run_random_search_for_config(config: dict) -> dict:\n",
    "    best_accuracy, best_config, current_config = 0, deepcopy(config), deepcopy(config)\n",
    "    step_size, bad_step_counter, good_step_counter = 0.1, 0, 0\n",
    "    for num_trial in range(100):\n",
    "        result = run_model_for_config(current_config, best_accuracy=best_accuracy)\n",
    "\n",
    "        if result[\"accuracy\"] > best_accuracy:\n",
    "            bad_step_counter = 0\n",
    "            good_step_counter += 1\n",
    "\n",
    "            best_accuracy, best_config = result[\"accuracy\"], deepcopy(current_config)\n",
    "        else:\n",
    "            bad_step_counter += 1\n",
    "            good_step_counter = 0\n",
    "\n",
    "        if bad_step_counter > 10:\n",
    "            break  # Terminate run, likely no better accuracy possible\n",
    "\n",
    "        current_config, step_size, bad_step_counter, good_step_counter = adaptive_step_update_config(\n",
    "            config=deepcopy(best_config),\n",
    "            step_size=step_size,\n",
    "            bad_step_counter=bad_step_counter,\n",
    "            good_step_counter=good_step_counter,\n",
    "        )\n",
    "\n",
    "        if step_size < 1e-2:\n",
    "            # Step size too small to make any impact, terminate run\n",
    "            break\n",
    "\n",
    "    return {\"accuracy\": best_accuracy, \"config\": best_config}\n",
    "\n",
    "\n",
    "def adaptive_step_update_config(\n",
    "        config: dict,\n",
    "        step_size: float,\n",
    "        bad_step_counter: int,\n",
    "        good_step_counter: int,\n",
    ") -> tuple[dict, float, int, int]:\n",
    "    # Update step_size\n",
    "    if bad_step_counter > 2:\n",
    "        step_size /= 2\n",
    "        bad_step_counter = 0\n",
    "    if (good_step_counter > 2) and (step_size < 0.5):\n",
    "        step_size *= 2\n",
    "        good_step_counter = 0\n",
    "\n",
    "    # Update config values\n",
    "    config[\"viterbi_lr\"] = uniform(\n",
    "        config[\"viterbi_lr\"] * (1 - step_size),\n",
    "        config[\"viterbi_lr\"] * (1 + step_size),\n",
    "    )\n",
    "    config[\"lukasiewicz_lr\"] = uniform(\n",
    "        config[\"lukasiewicz_lr\"] * (1 - step_size),\n",
    "        config[\"lukasiewicz_lr\"] * (1 + step_size),\n",
    "    )\n",
    "\n",
    "    return config, step_size, bad_step_counter, good_step_counter\n",
    "\n",
    "\n",
    "def find_best_model_for(config: dict) -> None:\n",
    "    current_config, results = deepcopy(config), []\n",
    "\n",
    "    for reverse in [True, False]:\n",
    "        current_config[\"reverse\"] = reverse\n",
    "        for viterbi_scheduler in [True, False]:\n",
    "            current_config[\"viterbi_scheduler\"] = viterbi_scheduler\n",
    "            for lukasiewicz_scheduler in [True, False]:\n",
    "                current_config[\"lukasiewicz_scheduler\"] = lukasiewicz_scheduler\n",
    "\n",
    "                result, counter = {\"accuracy\": 0, \"config\": {}}, 0\n",
    "                while counter < 5:\n",
    "                    current_config = create_random_config_for_model(deepcopy(current_config))\n",
    "                    print(f\"Starting semiring run for config {current_config}\")\n",
    "                    subresult = run_random_search_for_config(current_config)\n",
    "                    if subresult[\"accuracy\"] > result[\"accuracy\"]:\n",
    "                        result = subresult\n",
    "                    counter += 1\n",
    "\n",
    "                display.clear_output(wait=True)\n",
    "                results.append(result)\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda dictionary: dictionary[\"accuracy\"], reverse=True)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    print(f'Best trial config with accuracy of {sorted_results[0][\"accuracy\"]}: {sorted_results[0][\"config\"]}')\n",
    "    print(f\"-----------------\")\n",
    "    print(*sorted_results, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def create_random_config_for_model(config: dict) -> dict:\n",
    "    config[\"viterbi_lr\"] = 10 ** uniform(-3, -1)\n",
    "    config[\"lukasiewicz_lr\"] = 10 ** uniform(-3, -1)\n",
    "\n",
    "    return config"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "find_best_model_for(config={\n",
    "    \"dataset\": \"iris\",\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
